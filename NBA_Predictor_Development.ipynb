{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YCjdbkhXWvt",
        "outputId": "b9327436-6a93-4b40-f798-dd5d674dad45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Created: data/raw\n",
            "✓ Created: data/processed\n",
            "✓ Created: features\n",
            "✓ Created: models\n",
            "✓ Created: evaluation\n",
            "✓ Created: notebooks\n",
            "✓ Created: simulation\n",
            "\n",
            "✓ Working directory set to: /content/drive/MyDrive/nba_predictor\n",
            "Installing dependencies...\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ All dependencies installed successfully\n",
            "\n",
            "✓ nba_api imported successfully\n",
            "✓ pandas version: 2.2.2\n",
            "✓ numpy version: 2.0.2\n",
            "✓ scikit-learn version: 1.6.1\n",
            "✓ xgboost version: 3.1.2\n",
            "✓ matplotlib version: 3.10.0\n",
            "✓ plotly version: 5.24.1\n",
            "✓ Core libraries imported\n",
            "✓ Display settings configured\n",
            "✓ Helper functions defined\n",
            "✓ Project configuration loaded\n",
            "\n",
            "Configuration:\n",
            "  seasons: ['2021-22', '2022-23', '2023-24']\n",
            "  train_seasons: ['2021-22', '2022-23']\n",
            "  test_season: 2023-24\n",
            "  rolling_windows: [5, 10]\n",
            "  primary_window: 5\n",
            "  random_seed: 42\n",
            "  n_simulations: 10000\n",
            "Testing NBA API connection...\n",
            "✓ Successfully retrieved 30 NBA teams\n",
            "✓ Successfully retrieved sample data: 2460 rows\n",
            "\n",
            "Sample teams:\n",
            "  Atlanta Hawks (ATL)\n",
            "  Boston Celtics (BOS)\n",
            "  Cleveland Cavaliers (CLE)\n",
            "  New Orleans Pelicans (NOP)\n",
            "  Chicago Bulls (CHI)\n",
            "\n",
            "✓ NBA API connection successful!\n",
            "✓ Team lookup created with 30 teams\n",
            "✓ Team reference saved to data/raw/team_reference.csv\n",
            "\n",
            "Sample team mappings:\n",
            "  1610612737: ATL - Atlanta Hawks\n",
            "  1610612738: BOS - Boston Celtics\n",
            "  1610612739: CLE - Cleveland Cavaliers\n",
            "  1610612740: NOP - New Orleans Pelicans\n",
            "  1610612741: CHI - Chicago Bulls\n",
            "\n",
            "============================================================\n",
            "ENVIRONMENT SETUP COMPLETE\n",
            "============================================================\n",
            "\n",
            "✓ Google Drive mounted\n",
            "✓ Project directory: /content/drive/MyDrive/nba_predictor\n",
            "✓ Directory structure created\n",
            "✓ Dependencies installed and verified\n",
            "✓ Helper functions loaded\n",
            "✓ Configuration set\n",
            "✓ NBA API connection tested\n",
            "✓ Team lookup created\n",
            "\n",
            "============================================================\n",
            "READY TO BEGIN DATA COLLECTION\n",
            "============================================================\n",
            "\n",
            "Next steps:\n",
            "1. Run the data collection script (Week 1, Day 1-2)\n",
            "2. All data will be saved to your Google Drive\n",
            "3. Progress will persist across Colab sessions\n",
            "\n",
            "⚠ IMPORTANT REMINDERS:\n",
            "  • Never shuffle data randomly - always use time-based splits\n",
            "  • Save checkpoints frequently to Drive\n",
            "  • Verify no data leakage at each step\n",
            "  • Check for missing values before modeling\n"
          ]
        }
      ],
      "source": [
        "# NBA Win Probability Predictor - Colab Setup\n",
        "# Run this cell first in your Google Colab notebook\n",
        "\n",
        "\"\"\"\n",
        "This notebook sets up the complete environment for the NBA prediction project.\n",
        "Run each cell in order.\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 1: Mount Google Drive (for persistent storage)\n",
        "# =============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory structure in Drive\n",
        "project_root = '/content/drive/MyDrive/nba_predictor'\n",
        "\n",
        "directories = [\n",
        "    'data/raw',\n",
        "    'data/processed',\n",
        "    'features',\n",
        "    'models',\n",
        "    'evaluation',\n",
        "    'notebooks',\n",
        "    'simulation'\n",
        "]\n",
        "\n",
        "for dir_path in directories:\n",
        "    full_path = os.path.join(project_root, dir_path)\n",
        "    os.makedirs(full_path, exist_ok=True)\n",
        "    print(f\"✓ Created: {dir_path}\")\n",
        "\n",
        "# Set working directory\n",
        "os.chdir(project_root)\n",
        "print(f\"\\n✓ Working directory set to: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 2: Install Dependencies (Minimal, Professional)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Installing dependencies...\\n\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q nba_api pandas numpy scikit-learn xgboost lightgbm matplotlib plotly kaleido\n",
        "\n",
        "# CELL 2 (FIXED): Verify installations\n",
        "\n",
        "print(\"✓ All dependencies installed successfully\")\n",
        "\n",
        "# Verify installations\n",
        "import nba_api\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import matplotlib\n",
        "import plotly\n",
        "\n",
        "print(f\"\\n✓ nba_api imported successfully\")\n",
        "print(f\"✓ pandas version: {pd.__version__}\")\n",
        "print(f\"✓ numpy version: {np.__version__}\")\n",
        "print(f\"✓ scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"✓ xgboost version: {xgb.__version__}\")\n",
        "print(f\"✓ matplotlib version: {matplotlib.__version__}\")\n",
        "print(f\"✓ plotly version: {plotly.__version__}\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 3: Import Core Libraries\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.3f}'.format)\n",
        "\n",
        "# Set matplotlib style\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"✓ Core libraries imported\")\n",
        "print(\"✓ Display settings configured\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4: Helper Functions for Data Management\n",
        "# =============================================================================\n",
        "\n",
        "def save_checkpoint(df, filename, description=\"\"):\n",
        "    \"\"\"Save dataframe to Drive with timestamp\"\"\"\n",
        "    filepath = os.path.join(project_root, 'data/processed', filename)\n",
        "    df.to_csv(filepath, index=False)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"✓ [{timestamp}] Saved: {filename}\")\n",
        "    if description:\n",
        "        print(f\"  {description}\")\n",
        "    print(f\"  Shape: {df.shape}\")\n",
        "    return filepath\n",
        "\n",
        "def load_checkpoint(filename):\n",
        "    \"\"\"Load dataframe from Drive\"\"\"\n",
        "    filepath = os.path.join(project_root, 'data/processed', filename)\n",
        "    if os.path.exists(filepath):\n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"✓ Loaded: {filename}\")\n",
        "        print(f\"  Shape: {df.shape}\")\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"✗ File not found: {filename}\")\n",
        "        return None\n",
        "\n",
        "def verify_no_leakage(df, date_col='game_date'):\n",
        "    \"\"\"Verify data is sorted chronologically\"\"\"\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    is_sorted = df[date_col].is_monotonic_increasing\n",
        "\n",
        "    if is_sorted:\n",
        "        print(\"✓ Data is properly sorted chronologically\")\n",
        "        print(f\"  Date range: {df[date_col].min()} to {df[date_col].max()}\")\n",
        "    else:\n",
        "        print(\"✗ WARNING: Data is NOT sorted chronologically!\")\n",
        "        print(\"  This could cause data leakage!\")\n",
        "\n",
        "    return is_sorted\n",
        "\n",
        "def check_missing_values(df, name=\"DataFrame\"):\n",
        "    \"\"\"Check for missing values\"\"\"\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df)) * 100\n",
        "\n",
        "    if missing.sum() == 0:\n",
        "        print(f\"✓ {name}: No missing values\")\n",
        "    else:\n",
        "        print(f\"⚠ {name}: Missing values detected\")\n",
        "        missing_df = pd.DataFrame({\n",
        "            'column': missing.index,\n",
        "            'missing_count': missing.values,\n",
        "            'missing_pct': missing_pct.values\n",
        "        })\n",
        "        missing_df = missing_df[missing_df['missing_count'] > 0].sort_values(\n",
        "            'missing_count', ascending=False\n",
        "        )\n",
        "        print(missing_df.to_string(index=False))\n",
        "\n",
        "print(\"✓ Helper functions defined\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 5: Project Configuration\n",
        "# =============================================================================\n",
        "\n",
        "# Project settings\n",
        "CONFIG = {\n",
        "    'seasons': ['2021-22', '2022-23', '2023-24'],\n",
        "    'train_seasons': ['2021-22', '2022-23'],\n",
        "    'test_season': '2023-24',\n",
        "    'rolling_windows': [5, 10],\n",
        "    'primary_window': 5,\n",
        "    'random_seed': 42,\n",
        "    'n_simulations': 10000\n",
        "}\n",
        "\n",
        "print(\"✓ Project configuration loaded\")\n",
        "print(\"\\nConfiguration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 6: Test NBA API Connection\n",
        "# =============================================================================\n",
        "\n",
        "from nba_api.stats.static import teams\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "\n",
        "print(\"Testing NBA API connection...\")\n",
        "\n",
        "try:\n",
        "    # Test 1: Get team list\n",
        "    nba_teams = teams.get_teams()\n",
        "    print(f\"✓ Successfully retrieved {len(nba_teams)} NBA teams\")\n",
        "\n",
        "    # Test 2: Get sample game data\n",
        "    gamefinder = leaguegamefinder.LeagueGameFinder(\n",
        "        season_nullable='2023-24',\n",
        "        league_id_nullable='00',\n",
        "        season_type_nullable='Regular Season'\n",
        "    )\n",
        "    sample_games = gamefinder.get_data_frames()[0]\n",
        "    print(f\"✓ Successfully retrieved sample data: {sample_games.shape[0]} rows\")\n",
        "\n",
        "    # Display sample teams\n",
        "    print(\"\\nSample teams:\")\n",
        "    for team in nba_teams[:5]:\n",
        "        print(f\"  {team['full_name']} ({team['abbreviation']})\")\n",
        "\n",
        "    print(\"\\n✓ NBA API connection successful!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"✗ NBA API connection failed: {str(e)}\")\n",
        "    print(\"  Check your internet connection and try again\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 7: Create Team Lookup Dictionary\n",
        "# =============================================================================\n",
        "\n",
        "# Create and save team lookup for consistent use\n",
        "nba_teams = teams.get_teams()\n",
        "team_lookup = {team['id']: team['abbreviation'] for team in nba_teams}\n",
        "team_name_lookup = {team['id']: team['full_name'] for team in nba_teams}\n",
        "\n",
        "# Save to Drive for reference\n",
        "team_df = pd.DataFrame(nba_teams)\n",
        "team_df.to_csv(os.path.join(project_root, 'data/raw/team_reference.csv'), index=False)\n",
        "\n",
        "print(f\"✓ Team lookup created with {len(team_lookup)} teams\")\n",
        "print(f\"✓ Team reference saved to data/raw/team_reference.csv\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample team mappings:\")\n",
        "for team_id, abbr in list(team_lookup.items())[:5]:\n",
        "    full_name = team_name_lookup[team_id]\n",
        "    print(f\"  {team_id}: {abbr} - {full_name}\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 8: Environment Verification Summary\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENVIRONMENT SETUP COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n✓ Google Drive mounted\")\n",
        "print(f\"✓ Project directory: {project_root}\")\n",
        "print(\"✓ Directory structure created\")\n",
        "print(\"✓ Dependencies installed and verified\")\n",
        "print(\"✓ Helper functions loaded\")\n",
        "print(\"✓ Configuration set\")\n",
        "print(\"✓ NBA API connection tested\")\n",
        "print(\"✓ Team lookup created\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"READY TO BEGIN DATA COLLECTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Run the data collection script (Week 1, Day 1-2)\")\n",
        "print(\"2. All data will be saved to your Google Drive\")\n",
        "print(\"3. Progress will persist across Colab sessions\")\n",
        "\n",
        "print(\"\\n⚠ IMPORTANT REMINDERS:\")\n",
        "print(\"  • Never shuffle data randomly - always use time-based splits\")\n",
        "print(\"  • Save checkpoints frequently to Drive\")\n",
        "print(\"  • Verify no data leakage at each step\")\n",
        "print(\"  • Check for missing values before modeling\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "STAGE 1 — RAW GAME INGESTION (PRODUCTION SAFE)\n",
        "\n",
        "Guarantees:\n",
        "- One row per game\n",
        "- No post-game box score leakage\n",
        "- Explicit integrity assertions\n",
        "- Chronologically sorted\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "import pandas as pd\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "from nba_api.stats.static import teams\n",
        "from requests.exceptions import Timeout, ConnectionError\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIG\n",
        "# =============================================================================\n",
        "\n",
        "CONFIG = {\n",
        "    \"seasons\": [\"2021-22\", \"2022-23\", \"2023-24\"],\n",
        "}\n",
        "\n",
        "SEASONS: List[str] = CONFIG[\"seasons\"]\n",
        "\n",
        "# Respectful to NBA API rate limits.\n",
        "# Randomized sleep avoids bot-like request patterns and reduces throttling risk.\n",
        "SLEEP_RANGE = (1.0, 2.5)\n",
        "\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — LOCK TEAM IDS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Locking team identifiers\")\n",
        "\n",
        "nba_teams = teams.get_teams()\n",
        "TEAM_ID_TO_ABBR = {t[\"id\"]: t[\"abbreviation\"] for t in nba_teams}\n",
        "\n",
        "assert len(TEAM_ID_TO_ABBR) == 30, \"Expected 30 NBA teams\"\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — SAFE API PULL\n",
        "# =============================================================================\n",
        "\n",
        "def pull_season_games(season: str) -> pd.DataFrame:\n",
        "    \"\"\"Pull raw team-game rows with retry + backoff.\"\"\"\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            print(f\"  Pulling {season} (attempt {attempt})\")\n",
        "\n",
        "            finder = leaguegamefinder.LeagueGameFinder(\n",
        "                season_nullable=season,\n",
        "                league_id_nullable=\"00\",\n",
        "                season_type_nullable=\"Regular Season\",\n",
        "            )\n",
        "\n",
        "            df = finder.get_data_frames()[0]\n",
        "\n",
        "            # lock identifiers immediately\n",
        "            df[\"team_abbr\"] = df[\"TEAM_ID\"].map(TEAM_ID_TO_ABBR)\n",
        "            df[\"season\"] = season\n",
        "\n",
        "            time.sleep(random.uniform(*SLEEP_RANGE))\n",
        "            return df\n",
        "\n",
        "        except (Timeout, ConnectionError) as e:\n",
        "            if attempt == MAX_RETRIES:\n",
        "                raise RuntimeError(f\"API failed for {season}\") from e\n",
        "            time.sleep(3 * attempt)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — COLLECT RAW TEAM-GAME DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Pulling raw data\")\n",
        "\n",
        "team_game_rows = []\n",
        "\n",
        "for season in SEASONS:\n",
        "    df = pull_season_games(season)\n",
        "    team_game_rows.append(df)\n",
        "\n",
        "raw_games = pd.concat(team_game_rows, ignore_index=True)\n",
        "\n",
        "# integrity checks\n",
        "assert raw_games[\"GAME_ID\"].nunique() * 2 == len(raw_games), \\\n",
        "    \"Each GAME_ID must have exactly 2 team rows\"\n",
        "\n",
        "assert raw_games[\"team_abbr\"].isna().sum() == 0, \\\n",
        "    \"Missing team abbreviations detected\"\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — TRANSFORM TO GAME LEVEL (OUTCOMES ONLY)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Transforming to game-level rows\")\n",
        "\n",
        "raw_games[\"is_home\"] = raw_games[\"MATCHUP\"].str.contains(\"vs.\", na=False)\n",
        "\n",
        "home = raw_games[raw_games[\"is_home\"]].copy()\n",
        "away = raw_games[~raw_games[\"is_home\"]].copy()\n",
        "\n",
        "assert home[\"GAME_ID\"].nunique() == away[\"GAME_ID\"].nunique(), \\\n",
        "    \"Mismatch between home and away games\"\n",
        "\n",
        "games = home.merge(\n",
        "    away,\n",
        "    on=[\"GAME_ID\", \"GAME_DATE\", \"season\"],\n",
        "    suffixes=(\"_home\", \"_away\"),\n",
        "    validate=\"one_to_one\",\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — CLEAN, LEAK-SAFE SCHEMA\n",
        "# =============================================================================\n",
        "\n",
        "games = games.rename(columns={\n",
        "    \"GAME_ID\": \"game_id\",\n",
        "    \"GAME_DATE\": \"game_date\",\n",
        "    \"TEAM_ID_home\": \"home_team_id\",\n",
        "    \"TEAM_ID_away\": \"away_team_id\",\n",
        "    \"team_abbr_home\": \"home_team\",\n",
        "    \"team_abbr_away\": \"away_team\",\n",
        "    \"PTS_home\": \"home_score\",\n",
        "    \"PTS_away\": \"away_score\",\n",
        "})\n",
        "\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "games = games.sort_values(\"game_date\").reset_index(drop=True)\n",
        "\n",
        "games[\"home_win\"] = (games[\"home_score\"] > games[\"away_score\"]).astype(int)\n",
        "\n",
        "games = games[[\n",
        "    \"game_id\",\n",
        "    \"game_date\",\n",
        "    \"season\",\n",
        "    \"home_team_id\",\n",
        "    \"away_team_id\",\n",
        "    \"home_team\",\n",
        "    \"away_team\",\n",
        "    \"home_score\",\n",
        "    \"away_score\",\n",
        "    \"home_win\",\n",
        "]]\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — DATA QUALITY ASSERTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Running integrity checks\")\n",
        "\n",
        "# chronological\n",
        "assert games[\"game_date\"].is_monotonic_increasing, \\\n",
        "    \"Games not sorted chronologically\"\n",
        "\n",
        "# duplicate game protection\n",
        "assert games[\"game_id\"].nunique() == len(games), \\\n",
        "    \"Duplicate game_ids detected\"\n",
        "\n",
        "# win sanity\n",
        "home_win_rate = games[\"home_win\"].mean()\n",
        "assert 0.53 < home_win_rate < 0.67, \\\n",
        "    f\"Suspicious home win rate: {home_win_rate:.3f}\"\n",
        "\n",
        "# per-season sanity (accounts for COVID-shortened 2019-20)\n",
        "season_counts = games.groupby(\"season\").size()\n",
        "for season, n in season_counts.items():\n",
        "    if season == \"2019-20\":\n",
        "        assert 900 < n < 1100, \\\n",
        "            f\"{season}: {n} games is suspicious (COVID season)\"\n",
        "    else:\n",
        "        assert 1100 < n < 1300, \\\n",
        "            f\"{season}: {n} games is suspicious\"\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — SAVE\n",
        "# =============================================================================\n",
        "\n",
        "output_path = save_checkpoint(\n",
        "    games,\n",
        "    \"games_outcomes.csv\",\n",
        "    \"Leak-safe game-level outcomes (no box score features)\"\n",
        ")\n",
        "\n",
        "print(\"\\n✔ DATA INGESTION COMPLETE\")\n",
        "print(f\"✔ Games: {len(games)}\")\n",
        "print(f\"✔ Seasons: {len(SEASONS)}\")\n",
        "print(f\"✔ Home win rate: {home_win_rate:.3f}\")\n",
        "print(f\"✔ Saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9C8cwxTdFwq",
        "outputId": "fa13320c-a4e1-45c3-a009-59cd7c51c53b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] Locking team identifiers\n",
            "\n",
            "[2] Pulling raw data\n",
            "  Pulling 2021-22 (attempt 1)\n",
            "  Pulling 2022-23 (attempt 1)\n",
            "  Pulling 2023-24 (attempt 1)\n",
            "\n",
            "[3] Transforming to game-level rows\n",
            "\n",
            "[4] Running integrity checks\n",
            "✓ [2026-01-06 00:56:32] Saved: games_outcomes.csv\n",
            "  Leak-safe game-level outcomes (no box score features)\n",
            "  Shape: (3690, 10)\n",
            "\n",
            "✔ DATA INGESTION COMPLETE\n",
            "✔ Games: 3690\n",
            "✔ Seasons: 3\n",
            "✔ Home win rate: 0.556\n",
            "✔ Saved to: /content/drive/MyDrive/nba_predictor/data/processed/games_outcomes.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "STAGE 2 — CONTEXT FEATURES (LEAK-SAFE, PRODUCTION)\n",
        "\n",
        "Adds pre-game context known before tip-off:\n",
        "- Rest days (season-aware)\n",
        "- Back-to-back indicators\n",
        "- Rest advantage\n",
        "- Season opener flags\n",
        "\n",
        "Guarantees:\n",
        "- No future information leakage\n",
        "- Season boundaries respected\n",
        "- Multi-season safe\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD GAME OUTCOMES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading game outcomes\")\n",
        "\n",
        "games = load_checkpoint(\"games_outcomes.csv\")\n",
        "\n",
        "assert games is not None, \"games_outcomes.csv not found\"\n",
        "\n",
        "# ---------------- FIXED: enforce datetime ----------------\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"], errors=\"raise\")\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "assert games[\"game_date\"].is_monotonic_increasing, \"Games not sorted chronologically\"\n",
        "\n",
        "print(f\"✓ Loaded {len(games)} games\")\n",
        "print(f\"✓ Seasons: {games['season'].nunique()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — BUILD TEAM SCHEDULE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Building per-team schedules\")\n",
        "\n",
        "def build_team_schedule(games_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Each row = one team's participation in one game.\n",
        "    \"\"\"\n",
        "    home = games_df[[\"game_id\", \"game_date\", \"season\", \"home_team\"]].copy()\n",
        "    home = home.rename(columns={\"home_team\": \"team\"})\n",
        "    home[\"is_home\"] = 1\n",
        "\n",
        "    away = games_df[[\"game_id\", \"game_date\", \"season\", \"away_team\"]].copy()\n",
        "    away = away.rename(columns={\"away_team\": \"team\"})\n",
        "    away[\"is_home\"] = 0\n",
        "\n",
        "    schedule = pd.concat([home, away], ignore_index=True)\n",
        "    schedule = schedule.sort_values(\n",
        "        [\"team\", \"season\", \"game_date\"]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    return schedule\n",
        "\n",
        "team_schedule = build_team_schedule(games)\n",
        "\n",
        "print(f\"✓ Team-game rows: {len(team_schedule)}\")\n",
        "print(f\"✓ Teams: {team_schedule['team'].nunique()}\")\n",
        "\n",
        "# Season-aware sanity check\n",
        "seasons_loaded = games[\"season\"].nunique()\n",
        "expected_games = 82 * seasons_loaded\n",
        "games_per_team = team_schedule.groupby(\"team\").size()\n",
        "\n",
        "assert games_per_team.min() > expected_games * 0.90, \\\n",
        "    \"Suspiciously few games for at least one team\"\n",
        "\n",
        "assert games_per_team.max() < expected_games * 1.05, \\\n",
        "    \"Suspiciously many games for at least one team\"\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — COMPUTE REST DAYS (SEASON-AWARE)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Computing rest days\")\n",
        "\n",
        "def compute_rest_days(schedule: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Rest days logic:\n",
        "    - Computed only within season\n",
        "    - Season openers flagged explicitly\n",
        "    - Rest days capped only for missing previous games\n",
        "    \"\"\"\n",
        "    schedule = schedule.copy()\n",
        "\n",
        "    schedule[\"prev_game_date\"] = (\n",
        "        schedule\n",
        "        .groupby([\"team\", \"season\"])[\"game_date\"]\n",
        "        .shift(1)\n",
        "    )\n",
        "\n",
        "    schedule[\"is_season_opener\"] = schedule[\"prev_game_date\"].isna().astype(int)\n",
        "\n",
        "    schedule[\"rest_days\"] = (\n",
        "        schedule[\"game_date\"] - schedule[\"prev_game_date\"]\n",
        "    ).dt.days\n",
        "\n",
        "    # Season openers: cap rest (offseason gap is not informative)\n",
        "    schedule[\"rest_days\"] = schedule[\"rest_days\"].fillna(7).astype(int)\n",
        "\n",
        "    assert schedule[\"rest_days\"].min() >= 0, \"Negative rest days detected\"\n",
        "    assert schedule[\"rest_days\"].max() <= 30, \"Unrealistic rest days detected\"\n",
        "\n",
        "    return schedule\n",
        "\n",
        "team_schedule = compute_rest_days(team_schedule)\n",
        "\n",
        "print(\n",
        "    f\"✓ Rest days range: \"\n",
        "    f\"{team_schedule['rest_days'].min()}–{team_schedule['rest_days'].max()}\"\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — BACK-TO-BACK INDICATOR\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Computing back-to-back flags\")\n",
        "\n",
        "team_schedule[\"is_back_to_back\"] = (team_schedule[\"rest_days\"] == 1).astype(int)\n",
        "\n",
        "# Validate per season (not averaged away)\n",
        "b2b_by_season = team_schedule.groupby(\"season\")[\"is_back_to_back\"].mean()\n",
        "\n",
        "assert b2b_by_season.between(0.12, 0.30).all(), \\\n",
        "    f\"Suspicious B2B rate detected:\\n{b2b_by_season}\"\n",
        "\n",
        "print(\"✓ Back-to-back rates by season:\")\n",
        "print(b2b_by_season.round(3))\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — MERGE CONTEXT BACK TO GAME LEVEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Merging context features\")\n",
        "\n",
        "context_cols = [\"game_id\", \"team\", \"rest_days\", \"is_back_to_back\", \"is_season_opener\"]\n",
        "\n",
        "# Home merge\n",
        "games = games.merge(\n",
        "    team_schedule[context_cols],\n",
        "    left_on=[\"game_id\", \"home_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\")\n",
        "\n",
        "games = games.rename(columns={\n",
        "    \"rest_days\": \"home_rest_days\",\n",
        "    \"is_back_to_back\": \"home_b2b\",\n",
        "    \"is_season_opener\": \"home_season_opener\"\n",
        "})\n",
        "\n",
        "# Away merge\n",
        "games = games.merge(\n",
        "    team_schedule[context_cols],\n",
        "    left_on=[\"game_id\", \"away_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\")\n",
        "\n",
        "games = games.rename(columns={\n",
        "    \"rest_days\": \"away_rest_days\",\n",
        "    \"is_back_to_back\": \"away_b2b\",\n",
        "    \"is_season_opener\": \"away_season_opener\"\n",
        "})\n",
        "\n",
        "# Missing-value protection\n",
        "context_features = [\n",
        "    \"home_rest_days\", \"away_rest_days\",\n",
        "    \"home_b2b\", \"away_b2b\",\n",
        "    \"home_season_opener\", \"away_season_opener\"\n",
        "]\n",
        "\n",
        "assert games[context_features].isna().sum().sum() == 0, \\\n",
        "    \"Missing context features detected\"\n",
        "\n",
        "print(\"✓ Context features merged cleanly\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — RELATIVE CONTEXT FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Computing relative features\")\n",
        "\n",
        "games[\"rest_advantage\"] = games[\"home_rest_days\"] - games[\"away_rest_days\"]\n",
        "games[\"both_b2b\"] = (\n",
        "    (games[\"home_b2b\"] == 1) & (games[\"away_b2b\"] == 1)\n",
        ").astype(int)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — VALIDATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Validating distributions\")\n",
        "\n",
        "print(f\"Mean rest advantage: {games['rest_advantage'].mean():.3f}\")\n",
        "print(f\"Both teams B2B rate: {games['both_b2b'].mean():.3f}\")\n",
        "\n",
        "# NOTE:\n",
        "# Correlations below are diagnostic only.\n",
        "# They do NOT indicate model usefulness or causality.\n",
        "\n",
        "print(\"\\nContext correlations with home_win (diagnostic only):\")\n",
        "print(\n",
        "    games[\n",
        "        context_features + [\"rest_advantage\", \"both_b2b\", \"home_win\"]\n",
        "    ]\n",
        "    .corr()[\"home_win\"]\n",
        "    .drop(\"home_win\")\n",
        "    .sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — SAVE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Saving enriched dataset\")\n",
        "\n",
        "output_path = save_checkpoint(\n",
        "    games,\n",
        "    \"games_with_context.csv\",\n",
        "    \"Leak-safe game outcomes with rest & back-to-back context\"\n",
        ")\n",
        "\n",
        "print(\"\\n✔ CONTEXT FEATURES COMPLETE\")\n",
        "print(f\"✔ Games: {len(games)}\")\n",
        "print(f\"✔ Features added: {len(context_features) + 2}\")\n",
        "print(f\"✔ Saved to: {output_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"READY FOR STAGE 3 — ROLLING PERFORMANCE FEATURES\")\n",
        "print(\"=\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uhy4vKVfHPn",
        "outputId": "1e1d609a-ec3c-48b0-9285-85133fed6b9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] Loading game outcomes\n",
            "✓ Loaded: games_outcomes.csv\n",
            "  Shape: (3690, 10)\n",
            "✓ Loaded 3690 games\n",
            "✓ Seasons: 3\n",
            "\n",
            "[2] Building per-team schedules\n",
            "✓ Team-game rows: 7380\n",
            "✓ Teams: 30\n",
            "\n",
            "[3] Computing rest days\n",
            "✓ Rest days range: 1–9\n",
            "\n",
            "[4] Computing back-to-back flags\n",
            "✓ Back-to-back rates by season:\n",
            "season\n",
            "2021-22   0.172\n",
            "2022-23   0.163\n",
            "2023-24   0.172\n",
            "Name: is_back_to_back, dtype: float64\n",
            "\n",
            "[5] Merging context features\n",
            "✓ Context features merged cleanly\n",
            "\n",
            "[6] Computing relative features\n",
            "\n",
            "[7] Validating distributions\n",
            "Mean rest advantage: 0.102\n",
            "Both teams B2B rate: 0.043\n",
            "\n",
            "Context correlations with home_win (diagnostic only):\n",
            "rest_advantage        0.060\n",
            "away_b2b              0.050\n",
            "home_rest_days        0.038\n",
            "both_b2b              0.011\n",
            "home_season_opener    0.008\n",
            "away_season_opener    0.002\n",
            "away_rest_days       -0.018\n",
            "home_b2b             -0.057\n",
            "Name: home_win, dtype: float64\n",
            "\n",
            "[8] Saving enriched dataset\n",
            "✓ [2026-01-06 00:56:33] Saved: games_with_context.csv\n",
            "  Leak-safe game outcomes with rest & back-to-back context\n",
            "  Shape: (3690, 18)\n",
            "\n",
            "✔ CONTEXT FEATURES COMPLETE\n",
            "✔ Games: 3690\n",
            "✔ Features added: 8\n",
            "✔ Saved to: /content/drive/MyDrive/nba_predictor/data/processed/games_with_context.csv\n",
            "\n",
            "============================================================\n",
            "READY FOR STAGE 3 — ROLLING PERFORMANCE FEATURES\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "STAGE 3 — ROLLING PERFORMANCE FEATURES (CACHED, PRODUCTION)\n",
        "\n",
        "Computes rolling team performance metrics using ONLY past games.\n",
        "All computations happen once and are cached for fast lookups.\n",
        "\n",
        "Features computed (per window):\n",
        "- Points scored/allowed (offensive/defensive ratings proxy)\n",
        "- Net rating (scored - allowed)\n",
        "- Win rate\n",
        "- Games in rolling window\n",
        "\n",
        "Guarantees:\n",
        "- No data leakage (only past games used)\n",
        "- Season boundaries respected\n",
        "- Early-season partial windows handled safely\n",
        "- Aggressive caching (no recomputation)\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIG FALLBACK\n",
        "# =============================================================================\n",
        "\n",
        "if \"CONFIG\" not in globals():\n",
        "    CONFIG = {\"rolling_windows\": [5, 10], \"primary_window\": 5}\n",
        "\n",
        "WINDOWS = CONFIG.get(\"rolling_windows\", [5, 10])\n",
        "PRIMARY_WINDOW = CONFIG.get(\"primary_window\", 5)\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD GAMES WITH CONTEXT\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading games with context\")\n",
        "\n",
        "games = load_checkpoint(\"games_with_context.csv\")\n",
        "assert games is not None, \"games_with_context.csv not found\"\n",
        "\n",
        "# Enforce proper date type\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"], errors=\"raise\")\n",
        "assert games[\"game_date\"].is_monotonic_increasing, \"Games not sorted chronologically\"\n",
        "\n",
        "print(f\"✓ Loaded {len(games)} games from {games['season'].nunique()} seasons\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — BUILD TEAM GAME LOG\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Building team game logs\")\n",
        "\n",
        "def build_team_game_log(games_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Each row = one team's stats from one game\n",
        "    \"\"\"\n",
        "    # Home games\n",
        "    home_log = games_df[[\n",
        "        \"game_id\", \"game_date\", \"season\",\n",
        "        \"home_team\", \"away_team\",\n",
        "        \"home_score\", \"away_score\"\n",
        "    ]].copy()\n",
        "\n",
        "    home_log = home_log.rename(columns={\n",
        "        \"home_team\": \"team\",\n",
        "        \"away_team\": \"opponent\",\n",
        "        \"home_score\": \"pts_scored\",\n",
        "        \"away_score\": \"pts_allowed\"\n",
        "    })\n",
        "    home_log[\"is_home\"] = 1\n",
        "\n",
        "    # Away games\n",
        "    away_log = games_df[[\n",
        "        \"game_id\", \"game_date\", \"season\",\n",
        "        \"away_team\", \"home_team\",\n",
        "        \"away_score\", \"home_score\"\n",
        "    ]].copy()\n",
        "\n",
        "    away_log = away_log.rename(columns={\n",
        "        \"away_team\": \"team\",\n",
        "        \"home_team\": \"opponent\",\n",
        "        \"away_score\": \"pts_scored\",\n",
        "        \"home_score\": \"pts_allowed\"\n",
        "    })\n",
        "    away_log[\"is_home\"] = 0\n",
        "\n",
        "    # Combine and sort\n",
        "    team_log = pd.concat([home_log, away_log], ignore_index=True)\n",
        "    team_log = team_log.sort_values([\"team\", \"season\", \"game_date\"]).reset_index(drop=True)\n",
        "\n",
        "    # Derived metrics\n",
        "    team_log[\"net_rating\"] = team_log[\"pts_scored\"] - team_log[\"pts_allowed\"]\n",
        "    team_log[\"won\"] = (team_log[\"pts_scored\"] > team_log[\"pts_allowed\"]).astype(int)\n",
        "\n",
        "    # Ensure numeric types\n",
        "    numeric_cols = [\"pts_scored\", \"pts_allowed\", \"net_rating\", \"won\"]\n",
        "    team_log[numeric_cols] = team_log[numeric_cols].apply(pd.to_numeric, errors=\"raise\")\n",
        "\n",
        "    return team_log\n",
        "\n",
        "team_log = build_team_game_log(games)\n",
        "\n",
        "print(f\"✓ Team game log: {len(team_log)} rows, {team_log['team'].nunique()} teams\")\n",
        "print(f\"✓ Date range: {team_log['game_date'].min().date()} to {team_log['game_date'].max().date()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — PRECOMPUTE ROLLING STATS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Precomputing rolling statistics (past games only)\")\n",
        "\n",
        "def precompute_rolling_stats(team_log: pd.DataFrame, windows: list) -> pd.DataFrame:\n",
        "    log = team_log.copy()\n",
        "    grouped = log.groupby([\"team\", \"season\"])\n",
        "\n",
        "    for window in windows:\n",
        "        print(f\"    Rolling window: {window} games\")\n",
        "\n",
        "        log[f\"pts_scored_L{window}\"] = grouped[\"pts_scored\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        log[f\"pts_allowed_L{window}\"] = grouped[\"pts_allowed\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        log[f\"net_rating_L{window}\"] = grouped[\"net_rating\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        log[f\"win_rate_L{window}\"] = grouped[\"won\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        log[f\"games_in_window_L{window}\"] = grouped[\"won\"].shift(1).rolling(window, min_periods=1).count()\n",
        "\n",
        "    return log\n",
        "\n",
        "team_log = precompute_rolling_stats(team_log, WINDOWS)\n",
        "\n",
        "rolling_cols = [c for c in team_log.columns if \"_L\" in c]\n",
        "nan_counts = team_log[rolling_cols].isna().sum()\n",
        "if nan_counts.sum() > 0:\n",
        "    print(\"⚠ NaNs detected in rolling stats (expected for early-season games)\")\n",
        "else:\n",
        "    print(\"✓ No NaNs in rolling stats\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — SAVE ROLLING STATS CACHE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Saving rolling stats cache\")\n",
        "\n",
        "cache_path = save_checkpoint(team_log, \"team_rolling_stats_cache.csv\",\n",
        "                             \"Precomputed rolling stats for all teams/dates\")\n",
        "\n",
        "print(f\"✓ Cache saved: {cache_path}, rows: {len(team_log)}, columns: {len(team_log.columns)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — MERGE TO GAME LEVEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Merging rolling stats into game-level data\")\n",
        "\n",
        "merge_cols = [\n",
        "    \"game_id\", \"team\",\n",
        "    f\"pts_scored_L{PRIMARY_WINDOW}\", f\"pts_allowed_L{PRIMARY_WINDOW}\",\n",
        "    f\"net_rating_L{PRIMARY_WINDOW}\", f\"win_rate_L{PRIMARY_WINDOW}\",\n",
        "    f\"games_in_window_L{PRIMARY_WINDOW}\"\n",
        "]\n",
        "\n",
        "# Home team\n",
        "games = games.merge(team_log[merge_cols], left_on=[\"game_id\", \"home_team\"],\n",
        "                    right_on=[\"game_id\", \"team\"], how=\"left\", validate=\"one_to_one\").drop(columns=\"team\")\n",
        "\n",
        "games = games.rename(columns={\n",
        "    f\"pts_scored_L{PRIMARY_WINDOW}\": f\"home_pts_L{PRIMARY_WINDOW}\",\n",
        "    f\"pts_allowed_L{PRIMARY_WINDOW}\": f\"home_pa_L{PRIMARY_WINDOW}\",\n",
        "    f\"net_rating_L{PRIMARY_WINDOW}\": f\"home_net_L{PRIMARY_WINDOW}\",\n",
        "    f\"win_rate_L{PRIMARY_WINDOW}\": f\"home_winpct_L{PRIMARY_WINDOW}\",\n",
        "    f\"games_in_window_L{PRIMARY_WINDOW}\": f\"home_games_L{PRIMARY_WINDOW}\"\n",
        "})\n",
        "\n",
        "# Away team\n",
        "games = games.merge(team_log[merge_cols], left_on=[\"game_id\", \"away_team\"],\n",
        "                    right_on=[\"game_id\", \"team\"], how=\"left\", validate=\"one_to_one\").drop(columns=\"team\")\n",
        "\n",
        "games = games.rename(columns={\n",
        "    f\"pts_scored_L{PRIMARY_WINDOW}\": f\"away_pts_L{PRIMARY_WINDOW}\",\n",
        "    f\"pts_allowed_L{PRIMARY_WINDOW}\": f\"away_pa_L{PRIMARY_WINDOW}\",\n",
        "    f\"net_rating_L{PRIMARY_WINDOW}\": f\"away_net_L{PRIMARY_WINDOW}\",\n",
        "    f\"win_rate_L{PRIMARY_WINDOW}\": f\"away_winpct_L{PRIMARY_WINDOW}\",\n",
        "    f\"games_in_window_L{PRIMARY_WINDOW}\": f\"away_games_L{PRIMARY_WINDOW}\"\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — SEASON-ZSCORE NORMALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Normalizing rolling stats within each season\")\n",
        "\n",
        "def normalize_within_season(df: pd.DataFrame, window: int) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    cols = [\n",
        "        f\"home_pts_L{window}\", f\"home_pa_L{window}\", f\"home_net_L{window}\",\n",
        "        f\"away_pts_L{window}\", f\"away_pa_L{window}\", f\"away_net_L{window}\"\n",
        "    ]\n",
        "\n",
        "    for col in cols:\n",
        "        df[f\"{col}_z\"] = df.groupby(\"season\")[col].transform(\n",
        "            lambda x: (x - x.mean()) / x.std(ddof=0) if x.std(ddof=0) != 0 else 0\n",
        "        )\n",
        "\n",
        "    return df\n",
        "\n",
        "games = normalize_within_season(games, PRIMARY_WINDOW)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — RELATIVE MATCHUP FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Computing matchup features\")\n",
        "\n",
        "games[f\"net_diff_L{PRIMARY_WINDOW}\"] = (\n",
        "    games[f\"home_net_L{PRIMARY_WINDOW}_z\"] - games[f\"away_net_L{PRIMARY_WINDOW}_z\"]\n",
        ")\n",
        "\n",
        "games[f\"off_vs_def_L{PRIMARY_WINDOW}\"] = (\n",
        "    games[f\"home_pts_L{PRIMARY_WINDOW}_z\"] - games[f\"away_pa_L{PRIMARY_WINDOW}_z\"]\n",
        ")\n",
        "\n",
        "games[f\"winpct_diff_L{PRIMARY_WINDOW}\"] = (\n",
        "    games[f\"home_winpct_L{PRIMARY_WINDOW}\"] - games[f\"away_winpct_L{PRIMARY_WINDOW}\"]\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — SAVE FINAL DATASET\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Saving games with rolling features\")\n",
        "\n",
        "output_path = save_checkpoint(\n",
        "    games,\n",
        "    \"games_with_rolling_features.csv\",\n",
        "    f\"Games with context + L{PRIMARY_WINDOW} rolling performance features\"\n",
        ")\n",
        "\n",
        "print(\"\\n✔ ROLLING FEATURES COMPLETE\")\n",
        "print(f\"✔ Games: {len(games)}\")\n",
        "print(f\"✔ Features added: {len([c for c in games.columns if '_L' in c]) + 3}\")\n",
        "print(f\"✔ Saved to: {output_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"READY FOR WEEK 3: MODELING & EVALUATION\")\n",
        "print(\"=\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4956RmojDv3",
        "outputId": "aa016cba-9c83-4f35-996f-a0209e1a6df8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] Loading games with context\n",
            "✓ Loaded: games_with_context.csv\n",
            "  Shape: (3690, 18)\n",
            "✓ Loaded 3690 games from 3 seasons\n",
            "\n",
            "[2] Building team game logs\n",
            "✓ Team game log: 7380 rows, 30 teams\n",
            "✓ Date range: 2021-10-19 to 2024-04-14\n",
            "\n",
            "[3] Precomputing rolling statistics (past games only)\n",
            "    Rolling window: 5 games\n",
            "    Rolling window: 10 games\n",
            "⚠ NaNs detected in rolling stats (expected for early-season games)\n",
            "\n",
            "[4] Saving rolling stats cache\n",
            "✓ [2026-01-06 00:56:34] Saved: team_rolling_stats_cache.csv\n",
            "  Precomputed rolling stats for all teams/dates\n",
            "  Shape: (7380, 20)\n",
            "✓ Cache saved: /content/drive/MyDrive/nba_predictor/data/processed/team_rolling_stats_cache.csv, rows: 7380, columns: 20\n",
            "\n",
            "[5] Merging rolling stats into game-level data\n",
            "\n",
            "[6] Normalizing rolling stats within each season\n",
            "\n",
            "[7] Computing matchup features\n",
            "\n",
            "[8] Saving games with rolling features\n",
            "✓ [2026-01-06 00:56:35] Saved: games_with_rolling_features.csv\n",
            "  Games with context + L5 rolling performance features\n",
            "  Shape: (3690, 37)\n",
            "\n",
            "✔ ROLLING FEATURES COMPLETE\n",
            "✔ Games: 3690\n",
            "✔ Features added: 22\n",
            "✔ Saved to: /content/drive/MyDrive/nba_predictor/data/processed/games_with_rolling_features.csv\n",
            "\n",
            "============================================================\n",
            "READY FOR WEEK 3: MODELING & EVALUATION\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "STAGE 4 — MODELING & EVALUATION (PRODUCTION)\n",
        "\n",
        "Builds and evaluates prediction models:\n",
        "1. Baseline: Training home win rate (honest constant)\n",
        "2. Logistic Regression: Linear baseline\n",
        "3. XGBoost: Primary model\n",
        "\n",
        "Evaluation metrics:\n",
        "- Accuracy (secondary)\n",
        "- Log Loss (primary)\n",
        "- Brier Score\n",
        "- Calibration\n",
        "\n",
        "Guarantees:\n",
        "- Time-based train/test split (no random shuffle)\n",
        "- Honest evaluation (no peeking at test set)\n",
        "- Multiple metrics (not just accuracy)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "import xgboost as xgb\n",
        "\n",
        "# ========================\n",
        "# GLOBAL CONFIG & DIRECTORIES\n",
        "# ========================\n",
        "CONFIG = {\n",
        "    \"primary_window\": 5,\n",
        "    \"train_seasons\": [\"2021-22\", \"2022-23\"],\n",
        "    \"val_fraction\": 0.1,  # fraction of training used as validation\n",
        "    \"test_season\": \"2023-24\",\n",
        "    \"random_seed\": 42,\n",
        "    \"rolling_windows\": [5, 10]\n",
        "}\n",
        "\n",
        "np.random.seed(CONFIG[\"random_seed\"])\n",
        "\n",
        "os.makedirs(\"evaluation\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# ========================\n",
        "# LOAD FEATURE-RICH DATASET\n",
        "# ========================\n",
        "print(\"\\n[1] Loading dataset with all features\")\n",
        "games = load_checkpoint(\"games_with_rolling_features.csv\")\n",
        "assert games is not None, \"games_with_rolling_features.csv not found\"\n",
        "\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "print(f\"✓ Loaded: {games.shape}\")\n",
        "print(f\"✓ Seasons: {games['season'].unique()}\")\n",
        "\n",
        "# ========================\n",
        "# DEFINE FEATURE SET\n",
        "# ========================\n",
        "PRIMARY_WINDOW = CONFIG.get(\"primary_window\", 5)\n",
        "\n",
        "context_features = [\n",
        "    \"home_rest_days\", \"away_rest_days\", \"rest_advantage\",\n",
        "    \"home_b2b\", \"away_b2b\", \"both_b2b\"\n",
        "]\n",
        "\n",
        "rolling_features = [\n",
        "    f\"home_pts_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"home_pa_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"home_net_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"away_pts_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"away_pa_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"away_net_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"home_winpct_L{PRIMARY_WINDOW}\",\n",
        "    f\"away_winpct_L{PRIMARY_WINDOW}\"\n",
        "]\n",
        "\n",
        "matchup_features = [\n",
        "    f\"net_diff_L{PRIMARY_WINDOW}\",\n",
        "    f\"off_vs_def_L{PRIMARY_WINDOW}\",\n",
        "    f\"winpct_diff_L{PRIMARY_WINDOW}\"\n",
        "]\n",
        "\n",
        "feature_cols = context_features + rolling_features + matchup_features\n",
        "print(f\"✓ Total features: {len(feature_cols)}\")\n",
        "\n",
        "# ========================\n",
        "# HANDLE MISSING VALUES\n",
        "# ========================\n",
        "X_full = games[feature_cols].copy()\n",
        "missing_counts = X_full.isna().sum()\n",
        "if missing_counts.sum() > 0:\n",
        "    print(\"\\n⚠ Missing values detected in features:\")\n",
        "    print(missing_counts[missing_counts > 0])\n",
        "    # Impute missing values with column mean\n",
        "    X_full = X_full.fillna(X_full.mean())\n",
        "    print(\"✓ Missing values imputed with column mean\")\n",
        "\n",
        "# Ensure features are float\n",
        "X_full = X_full.astype(float)\n",
        "y_full = games[\"home_win\"].copy()\n",
        "seasons_full = games[\"season\"].copy()\n",
        "\n",
        "# ========================\n",
        "# TIME-BASED TRAIN/VALIDATION/TEST SPLIT\n",
        "# ========================\n",
        "TRAIN_SEASONS = CONFIG.get(\"train_seasons\", [\"2021-22\", \"2022-23\"])\n",
        "TEST_SEASON = CONFIG.get(\"test_season\", \"2023-24\")\n",
        "VAL_FRACTION = CONFIG.get(\"val_fraction\", 0.1)\n",
        "\n",
        "train_mask = seasons_full.isin(TRAIN_SEASONS)\n",
        "test_mask = seasons_full == TEST_SEASON\n",
        "\n",
        "X_train_full = X_full[train_mask].reset_index(drop=True)\n",
        "y_train_full = y_full[train_mask].reset_index(drop=True)\n",
        "X_test = X_full[test_mask].reset_index(drop=True)\n",
        "y_test = y_full[test_mask].reset_index(drop=True)\n",
        "games_test = games[test_mask].reset_index(drop=True)\n",
        "\n",
        "# Split validation from training\n",
        "val_size = int(len(X_train_full) * VAL_FRACTION)\n",
        "X_train = X_train_full[:-val_size].reset_index(drop=True)\n",
        "y_train = y_train_full[:-val_size].reset_index(drop=True)\n",
        "X_val = X_train_full[-val_size:].reset_index(drop=True)\n",
        "y_val = y_train_full[-val_size:].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n✓ Train: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n",
        "print(f\"✓ Train home win rate: {y_train.mean():.3f}, Test home win rate: {y_test.mean():.3f}\")\n",
        "\n",
        "# ========================\n",
        "# BASELINE MODEL\n",
        "# ========================\n",
        "print(\"\\n[2] Baseline model (constant predictor)\")\n",
        "baseline_prob = y_train.mean()\n",
        "baseline_preds = np.full(len(y_test), baseline_prob)\n",
        "baseline_acc = accuracy_score(y_test, baseline_preds > 0.5)\n",
        "baseline_logloss = log_loss(y_test, baseline_preds)\n",
        "baseline_brier = brier_score_loss(y_test, baseline_preds)\n",
        "print(f\"Accuracy: {baseline_acc:.4f}, LogLoss: {baseline_logloss:.4f}, Brier: {baseline_brier:.4f}\")\n",
        "\n",
        "# ========================\n",
        "# LOGISTIC REGRESSION\n",
        "# ========================\n",
        "print(\"\\n[3] Logistic Regression\")\n",
        "lr = LogisticRegression(\n",
        "    penalty=\"l2\",\n",
        "    C=1.0,\n",
        "    max_iter=1000,\n",
        "    random_state=CONFIG[\"random_seed\"],\n",
        "    solver=\"lbfgs\"\n",
        ")\n",
        "lr.fit(X_train, y_train)\n",
        "lr_probs = lr.predict_proba(X_test)[:, 1]\n",
        "lr_acc = accuracy_score(y_test, lr_probs > 0.5)\n",
        "lr_logloss = log_loss(y_test, lr_probs)\n",
        "lr_brier = brier_score_loss(y_test, lr_probs)\n",
        "print(f\"Accuracy: {lr_acc:.4f}, LogLoss: {lr_logloss:.4f}, Brier: {lr_brier:.4f}\")\n",
        "\n",
        "# ========================\n",
        "# XGBOOST\n",
        "# ========================\n",
        "print(\"\\n[4] Training XGBoost\")\n",
        "xgb_params = {\n",
        "    \"max_depth\": 4,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"n_estimators\": 300,\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"logloss\",\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"random_state\": CONFIG[\"random_seed\"],\n",
        "    \"n_jobs\": -1,\n",
        "}\n",
        "\n",
        "# Safe early stopping with XGBoost versions: use callbacks if fit() doesn't accept early_stopping_rounds\n",
        "model = xgb.XGBClassifier(**xgb_params)\n",
        "\n",
        "try:\n",
        "    # Try the newer API\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        early_stopping_rounds=30,\n",
        "        verbose=False\n",
        "    )\n",
        "except TypeError:\n",
        "    # Fallback for older versions\n",
        "    print(\"⚠ early_stopping_rounds not supported by this XGBoost version; training without early stopping\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "xgb_probs = model.predict_proba(X_test)[:, 1]\n",
        "xgb_acc = accuracy_score(y_test, xgb_probs > 0.5)\n",
        "xgb_logloss = log_loss(y_test, xgb_probs)\n",
        "xgb_brier = brier_score_loss(y_test, xgb_probs)\n",
        "print(f\"Accuracy: {xgb_acc:.4f}, LogLoss: {xgb_logloss:.4f}, Brier: {xgb_brier:.4f}\")\n",
        "\n",
        "# ========================\n",
        "# FEATURE IMPORTANCE\n",
        "# ========================\n",
        "importance_gain = pd.DataFrame({\n",
        "    \"feature\": feature_cols,\n",
        "    \"importance\": model.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "importance_gain.to_csv(\"evaluation/feature_importance.csv\", index=False)\n",
        "print(\"✓ Feature importance saved to evaluation/feature_importance.csv\")\n",
        "\n",
        "# ========================\n",
        "# MODEL COMPARISON\n",
        "# ========================\n",
        "comparison = pd.DataFrame({\n",
        "    \"Model\": [\"Baseline\", \"Logistic Regression\", \"XGBoost\"],\n",
        "    \"Accuracy\": [baseline_acc, lr_acc, xgb_acc],\n",
        "    \"Log Loss\": [baseline_logloss, lr_logloss, xgb_logloss],\n",
        "    \"Brier Score\": [baseline_brier, lr_brier, xgb_brier]\n",
        "})\n",
        "print(\"\\n\" + comparison.to_string(index=False))\n",
        "best_model_idx = comparison[\"Log Loss\"].idxmin()\n",
        "best_model = comparison.loc[best_model_idx, \"Model\"]\n",
        "print(f\"\\n✓ Best model (by Log Loss): {best_model}\")\n",
        "\n",
        "# ========================\n",
        "# CALIBRATION ANALYSIS\n",
        "# ========================\n",
        "prob_true, prob_pred = calibration_curve(y_test, xgb_probs, n_bins=10, strategy=\"uniform\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\", linewidth=2)\n",
        "plt.plot(prob_pred, prob_true, \"o-\", label=\"XGBoost\", linewidth=2, markersize=8)\n",
        "plt.xlabel(\"Predicted Probability\")\n",
        "plt.ylabel(\"True Probability\")\n",
        "plt.title(\"Calibration Plot - XGBoost\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/calibration_curve.png\", dpi=150)\n",
        "plt.close()\n",
        "calibration_error = np.abs(prob_true - prob_pred).mean()\n",
        "print(f\"Mean calibration error: {calibration_error:.4f}\")\n",
        "\n",
        "# ========================\n",
        "# PREDICTION DISTRIBUTION\n",
        "# ========================\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(xgb_probs, bins=30, edgecolor=\"black\", alpha=0.7)\n",
        "plt.axvline(0.5, color=\"red\", linestyle=\"--\", linewidth=2)\n",
        "plt.xlabel(\"Predicted Home Win Probability\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of XGBoost Predictions\")\n",
        "plt.grid(axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/prediction_distribution.png\", dpi=150)\n",
        "plt.close()\n",
        "print(\"✓ Prediction distribution saved\")\n",
        "\n",
        "# Confidence analysis\n",
        "confident_correct = ((xgb_probs > 0.7) & (y_test == 1)).sum() + ((xgb_probs < 0.3) & (y_test == 0)).sum()\n",
        "confident_total = ((xgb_probs > 0.7) | (xgb_probs < 0.3)).sum()\n",
        "confident_acc = confident_correct / confident_total if confident_total > 0 else 0\n",
        "print(f\"High-confidence predictions: {confident_total} ({100*confident_total/len(y_test):.1f}%), Accuracy: {confident_acc:.3f}\")\n",
        "\n",
        "# ========================\n",
        "# SAVE RESULTS & MODEL\n",
        "# ========================\n",
        "results_path = save_checkpoint(\n",
        "    games_test.assign(predicted_home_win_prob=xgb_probs, actual_home_win=y_test),\n",
        "    \"test_predictions.csv\",\n",
        "    \"Test set with XGBoost predictions\"\n",
        ")\n",
        "\n",
        "# Use XGBoost native save_model for safety\n",
        "model_path = \"models/xgboost_model.json\"\n",
        "model.save_model(model_path)\n",
        "print(f\"✓ Model saved to {model_path}\")\n",
        "\n",
        "print(\"\\n✔ MODELING COMPLETE\")\n",
        "print(f\"✔ Best model: {best_model}\")\n",
        "print(f\"✔ Test accuracy: {xgb_acc:.4f}\")\n",
        "print(f\"✔ Test log loss: {xgb_logloss:.4f}\")\n",
        "print(f\"✔ Predictions saved: {results_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR7cA7GFj5k7",
        "outputId": "877744c2-3d27-49ee-9677-1a4241094bd2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] Loading dataset with all features\n",
            "✓ Loaded: games_with_rolling_features.csv\n",
            "  Shape: (3690, 37)\n",
            "✓ Loaded: (3690, 37)\n",
            "✓ Seasons: ['2021-22' '2022-23' '2023-24']\n",
            "✓ Total features: 17\n",
            "\n",
            "⚠ Missing values detected in features:\n",
            "home_pts_L5_z     1\n",
            "home_pa_L5_z      1\n",
            "home_net_L5_z     1\n",
            "home_winpct_L5    1\n",
            "net_diff_L5       1\n",
            "off_vs_def_L5     1\n",
            "winpct_diff_L5    1\n",
            "dtype: int64\n",
            "✓ Missing values imputed with column mean\n",
            "\n",
            "✓ Train: 2214, Validation: 246, Test: 1230\n",
            "✓ Train home win rate: 0.565, Test home win rate: 0.543\n",
            "\n",
            "[2] Baseline model (constant predictor)\n",
            "Accuracy: 0.5431, LogLoss: 0.6904, Brier: 0.2486\n",
            "\n",
            "[3] Logistic Regression\n",
            "Accuracy: 0.6138, LogLoss: 0.6576, Brier: 0.2327\n",
            "\n",
            "[4] Training XGBoost\n",
            "⚠ early_stopping_rounds not supported by this XGBoost version; training without early stopping\n",
            "Accuracy: 0.5886, LogLoss: 0.6892, Brier: 0.2465\n",
            "✓ Feature importance saved to evaluation/feature_importance.csv\n",
            "\n",
            "              Model  Accuracy  Log Loss  Brier Score\n",
            "           Baseline     0.543     0.690        0.249\n",
            "Logistic Regression     0.614     0.658        0.233\n",
            "            XGBoost     0.589     0.689        0.246\n",
            "\n",
            "✓ Best model (by Log Loss): Logistic Regression\n",
            "Mean calibration error: 0.1034\n",
            "✓ Prediction distribution saved\n",
            "High-confidence predictions: 392 (31.9%), Accuracy: 0.656\n",
            "✓ [2026-01-06 00:56:43] Saved: test_predictions.csv\n",
            "  Test set with XGBoost predictions\n",
            "  Shape: (1230, 39)\n",
            "✓ Model saved to models/xgboost_model.json\n",
            "\n",
            "✔ MODELING COMPLETE\n",
            "✔ Best model: Logistic Regression\n",
            "✔ Test accuracy: 0.5886\n",
            "✔ Test log loss: 0.6892\n",
            "✔ Predictions saved: /content/drive/MyDrive/nba_predictor/data/processed/test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "STAGE 4B — XGBOOST FIX (PROPER VALIDATION)\n",
        "\n",
        "Fixes XGBoost training with proper early stopping using the native API.\n",
        "The sklearn wrapper has compatibility issues with early stopping.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"XGBOOST RETRAIN - FIXED VERSION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD PREVIOUS RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading previous train/test split\")\n",
        "\n",
        "# Reload the dataset\n",
        "games = load_checkpoint(\"games_with_rolling_features.csv\")\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "\n",
        "# Recreate the exact same split\n",
        "PRIMARY_WINDOW = 5\n",
        "TRAIN_SEASONS = [\"2021-22\", \"2022-23\"]\n",
        "TEST_SEASON = \"2023-24\"\n",
        "\n",
        "context_features = [\n",
        "    \"home_rest_days\", \"away_rest_days\", \"rest_advantage\",\n",
        "    \"home_b2b\", \"away_b2b\", \"both_b2b\"\n",
        "]\n",
        "\n",
        "rolling_features = [\n",
        "    f\"home_pts_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"home_pa_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"home_net_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"away_pts_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"away_pa_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"away_net_L{PRIMARY_WINDOW}_z\",\n",
        "    f\"home_winpct_L{PRIMARY_WINDOW}\",\n",
        "    f\"away_winpct_L{PRIMARY_WINDOW}\"\n",
        "]\n",
        "\n",
        "matchup_features = [\n",
        "    f\"net_diff_L{PRIMARY_WINDOW}\",\n",
        "    f\"off_vs_def_L{PRIMARY_WINDOW}\",\n",
        "    f\"winpct_diff_L{PRIMARY_WINDOW}\"\n",
        "]\n",
        "\n",
        "feature_cols = context_features + rolling_features + matchup_features\n",
        "\n",
        "X = games[feature_cols].copy().fillna(games[feature_cols].mean()).astype(float)\n",
        "y = games[\"home_win\"].copy()\n",
        "seasons = games[\"season\"].copy()\n",
        "\n",
        "train_mask = seasons.isin(TRAIN_SEASONS)\n",
        "test_mask = seasons == TEST_SEASON\n",
        "\n",
        "X_train_full = X[train_mask].reset_index(drop=True)\n",
        "y_train_full = y[train_mask].reset_index(drop=True)\n",
        "X_test = X[test_mask].reset_index(drop=True)\n",
        "y_test = y[test_mask].reset_index(drop=True)\n",
        "\n",
        "# Create validation set (last 10% of training)\n",
        "val_size = int(len(X_train_full) * 0.1)\n",
        "X_val = X_train_full.iloc[-val_size:].reset_index(drop=True)\n",
        "y_val = y_train_full.iloc[-val_size:].reset_index(drop=True)\n",
        "X_train = X_train_full.iloc[:-val_size].reset_index(drop=True)\n",
        "y_train = y_train_full.iloc[:-val_size].reset_index(drop=True)\n",
        "\n",
        "print(f\"✓ Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# XGBOOST USING NATIVE API (PROPER EARLY STOPPING)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Training XGBoost with native API (proper early stopping)\")\n",
        "\n",
        "# Convert to DMatrix format\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_cols)\n",
        "dval = xgb.DMatrix(X_val, label=y_val, feature_names=feature_cols)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=feature_cols)\n",
        "\n",
        "# XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'max_depth': 4,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "    'tree_method': 'hist'  # Faster training\n",
        "}\n",
        "\n",
        "# Train with early stopping\n",
        "print(\"  Training with early stopping...\")\n",
        "evals = [(dtrain, 'train'), (dval, 'val')]\n",
        "evals_result = {}\n",
        "\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=500,  # Max iterations\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=30,\n",
        "    evals_result=evals_result,\n",
        "    verbose_eval=50  # Print every 50 rounds\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Best iteration: {model.best_iteration}\")\n",
        "print(f\"✓ Best validation log loss: {model.best_score:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# EVALUATE ON TEST SET\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Evaluating on test set\")\n",
        "\n",
        "xgb_probs = model.predict(dtest)\n",
        "\n",
        "xgb_acc = accuracy_score(y_test, xgb_probs > 0.5)\n",
        "xgb_logloss = log_loss(y_test, xgb_probs)\n",
        "xgb_brier = brier_score_loss(y_test, xgb_probs)\n",
        "\n",
        "# Compare to baseline and logistic regression\n",
        "baseline_prob = y_train.mean()\n",
        "baseline_logloss = log_loss(y_test, np.full(len(y_test), baseline_prob))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON (UPDATED)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Model\": [\"Baseline\", \"Logistic Regression\", \"XGBoost (Fixed)\"],\n",
        "    \"Accuracy\": [0.543, 0.614, xgb_acc],\n",
        "    \"Log Loss\": [0.690, 0.658, xgb_logloss],\n",
        "    \"Brier Score\": [0.249, 0.233, xgb_brier]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison.to_string(index=False))\n",
        "\n",
        "# Improvement metrics\n",
        "print(f\"\\nXGBoost vs Baseline:\")\n",
        "print(f\"  Accuracy: {xgb_acc - 0.543:+.4f}\")\n",
        "print(f\"  Log Loss: {xgb_logloss - 0.690:+.4f}\")\n",
        "\n",
        "print(f\"\\nXGBoost vs Logistic Regression:\")\n",
        "print(f\"  Accuracy: {xgb_acc - 0.614:+.4f}\")\n",
        "print(f\"  Log Loss: {xgb_logloss - 0.658:+.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# FEATURE IMPORTANCE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Feature importance analysis\")\n",
        "\n",
        "# Get importance scores\n",
        "importance_dict = model.get_score(importance_type='gain')\n",
        "\n",
        "# Convert to dataframe\n",
        "importance_df = pd.DataFrame([\n",
        "    {'feature': k, 'importance': v}\n",
        "    for k, v in importance_dict.items()\n",
        "]).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 features:\")\n",
        "print(importance_df.head(10).to_string(index=False))\n",
        "\n",
        "# Save\n",
        "importance_df.to_csv(\"evaluation/feature_importance_fixed.csv\", index=False)\n",
        "\n",
        "# =============================================================================\n",
        "# CALIBRATION ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Calibration analysis\")\n",
        "\n",
        "prob_true, prob_pred = calibration_curve(y_test, xgb_probs, n_bins=10, strategy=\"uniform\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\", linewidth=2)\n",
        "plt.plot(prob_pred, prob_true, \"o-\", label=\"XGBoost (Fixed)\", linewidth=2, markersize=8)\n",
        "plt.xlabel(\"Predicted Probability\", fontsize=12)\n",
        "plt.ylabel(\"True Probability\", fontsize=12)\n",
        "plt.title(\"Calibration Plot - XGBoost (Fixed)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/calibration_curve_fixed.png\", dpi=150, bbox_inches=\"tight\")\n",
        "print(\"✓ Calibration plot saved\")\n",
        "plt.close()\n",
        "\n",
        "calibration_error = np.abs(prob_true - prob_pred).mean()\n",
        "print(f\"  Mean calibration error: {calibration_error:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING CURVE VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Plotting training curves\")\n",
        "\n",
        "train_logloss = evals_result['train']['logloss']\n",
        "val_logloss = evals_result['val']['logloss']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_logloss, label='Train', linewidth=2)\n",
        "plt.plot(val_logloss, label='Validation', linewidth=2)\n",
        "plt.axvline(model.best_iteration, color='red', linestyle='--', label=f'Best iteration ({model.best_iteration})')\n",
        "plt.xlabel('Iteration', fontsize=12)\n",
        "plt.ylabel('Log Loss', fontsize=12)\n",
        "plt.title('XGBoost Training Curve', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/training_curve.png\", dpi=150, bbox_inches=\"tight\")\n",
        "print(\"✓ Training curve saved\")\n",
        "plt.close()\n",
        "\n",
        "# =============================================================================\n",
        "# SAVE FIXED MODEL AND PREDICTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Saving fixed model and predictions\")\n",
        "\n",
        "# Save model\n",
        "model.save_model(\"models/xgboost_model_fixed.json\")\n",
        "print(\"✓ Model saved to models/xgboost_model_fixed.json\")\n",
        "\n",
        "# Save predictions\n",
        "test_results = games[test_mask].reset_index(drop=True).copy()\n",
        "test_results[\"predicted_home_win_prob\"] = xgb_probs\n",
        "test_results[\"actual_home_win\"] = y_test.values\n",
        "\n",
        "results_path = save_checkpoint(\n",
        "    test_results,\n",
        "    \"test_predictions_fixed.csv\",\n",
        "    \"Test predictions with fixed XGBoost model\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Predictions saved to {results_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# FINAL VERDICT\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if xgb_logloss < 0.658:\n",
        "    print(\"\\n✓ XGBoost now BEATS Logistic Regression!\")\n",
        "    print(f\"  XGBoost log loss: {xgb_logloss:.4f}\")\n",
        "    print(f\"  Logistic Regression log loss: 0.658\")\n",
        "    best_model = \"XGBoost\"\n",
        "else:\n",
        "    print(\"\\n→ Logistic Regression remains best model\")\n",
        "    print(f\"  Logistic Regression log loss: 0.658\")\n",
        "    print(f\"  XGBoost log loss: {xgb_logloss:.4f}\")\n",
        "    print(\"\\n  This is OKAY - simpler models sometimes win!\")\n",
        "    print(\"  Logistic Regression is:\")\n",
        "    print(\"    • Faster to train\")\n",
        "    print(\"    • More interpretable\")\n",
        "    print(\"    • Less prone to overfitting\")\n",
        "    best_model = \"Logistic Regression\"\n",
        "\n",
        "print(f\"\\n✔ Best model for deployment: {best_model}\")\n",
        "print(f\"✔ Test accuracy: {xgb_acc:.4f}\")\n",
        "print(f\"✔ Test log loss: {xgb_logloss:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"READY FOR WEEK 4: MONTE CARLO SIMULATION\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz6qS0CTlB0I",
        "outputId": "78b1c4f0-2538-4ad0-dddd-cabe2892cf8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "XGBOOST RETRAIN - FIXED VERSION\n",
            "============================================================\n",
            "\n",
            "[1] Loading previous train/test split\n",
            "✓ Loaded: games_with_rolling_features.csv\n",
            "  Shape: (3690, 37)\n",
            "✓ Train: 2214, Val: 246, Test: 1230\n",
            "\n",
            "[2] Training XGBoost with native API (proper early stopping)\n",
            "  Training with early stopping...\n",
            "[0]\ttrain-logloss:0.68137\tval-logloss:0.68776\n",
            "[50]\ttrain-logloss:0.60404\tval-logloss:0.65987\n",
            "[100]\ttrain-logloss:0.56425\tval-logloss:0.65789\n",
            "[138]\ttrain-logloss:0.53903\tval-logloss:0.66080\n",
            "\n",
            "✓ Best iteration: 108\n",
            "✓ Best validation log loss: 0.6576\n",
            "\n",
            "[3] Evaluating on test set\n",
            "\n",
            "============================================================\n",
            "MODEL COMPARISON (UPDATED)\n",
            "============================================================\n",
            "\n",
            "              Model  Accuracy  Log Loss  Brier Score\n",
            "           Baseline     0.543     0.690        0.249\n",
            "Logistic Regression     0.614     0.658        0.233\n",
            "    XGBoost (Fixed)     0.598     0.669        0.238\n",
            "\n",
            "XGBoost vs Baseline:\n",
            "  Accuracy: +0.0546\n",
            "  Log Loss: -0.0207\n",
            "\n",
            "XGBoost vs Logistic Regression:\n",
            "  Accuracy: -0.0164\n",
            "  Log Loss: +0.0113\n",
            "\n",
            "[4] Feature importance analysis\n",
            "\n",
            "Top 10 features:\n",
            "       feature  importance\n",
            "   net_diff_L5       5.791\n",
            "      home_b2b       4.460\n",
            " home_net_L5_z       4.134\n",
            "away_winpct_L5       4.047\n",
            "      both_b2b       4.035\n",
            " away_net_L5_z       3.975\n",
            "winpct_diff_L5       3.911\n",
            " off_vs_def_L5       3.731\n",
            "  home_pa_L5_z       3.668\n",
            "rest_advantage       3.651\n",
            "\n",
            "[5] Calibration analysis\n",
            "✓ Calibration plot saved\n",
            "  Mean calibration error: 0.0511\n",
            "\n",
            "[6] Plotting training curves\n",
            "✓ Training curve saved\n",
            "\n",
            "[7] Saving fixed model and predictions\n",
            "✓ Model saved to models/xgboost_model_fixed.json\n",
            "✓ [2026-01-06 00:56:49] Saved: test_predictions_fixed.csv\n",
            "  Test predictions with fixed XGBoost model\n",
            "  Shape: (1230, 39)\n",
            "✓ Predictions saved to /content/drive/MyDrive/nba_predictor/data/processed/test_predictions_fixed.csv\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS\n",
            "============================================================\n",
            "\n",
            "→ Logistic Regression remains best model\n",
            "  Logistic Regression log loss: 0.658\n",
            "  XGBoost log loss: 0.6693\n",
            "\n",
            "  This is OKAY - simpler models sometimes win!\n",
            "  Logistic Regression is:\n",
            "    • Faster to train\n",
            "    • More interpretable\n",
            "    • Less prone to overfitting\n",
            "\n",
            "✔ Best model for deployment: Logistic Regression\n",
            "✔ Test accuracy: 0.5976\n",
            "✔ Test log loss: 0.6693\n",
            "\n",
            "============================================================\n",
            "READY FOR WEEK 4: MONTE CARLO SIMULATION\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "STAGE 5 — MONTE CARLO SEASON SIMULATION\n",
        "\n",
        "Simulates season outcomes using predicted win probabilities.\n",
        "Preserves actual schedule structure (not independent Bernoullis).\n",
        "\n",
        "Outputs:\n",
        "- Expected wins per team\n",
        "- Win distribution uncertainty\n",
        "- Playoff probability estimates\n",
        "- Upset analysis\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from collections import defaultdict\n",
        "\n",
        "# =============================================================================\n",
        "# SETUP DIRECTORIES\n",
        "# =============================================================================\n",
        "\n",
        "Path(\"evaluation\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD CONFIG WITH FALLBACKS\n",
        "# =============================================================================\n",
        "\n",
        "N_SIMULATIONS = CONFIG.get(\"n_simulations\", 10000) if 'CONFIG' in globals() else 10000\n",
        "RANDOM_SEED = CONFIG.get(\"random_seed\", 42) if 'CONFIG' in globals() else 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD TEST PREDICTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MONTE CARLO SEASON SIMULATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[1] Loading test predictions\")\n",
        "\n",
        "try:\n",
        "    test_preds = load_checkpoint(\"test_predictions_fixed.csv\")\n",
        "    assert test_preds is not None\n",
        "except Exception as e:\n",
        "    raise FileNotFoundError(\"test_predictions_fixed.csv not found. Ensure predictions exist.\") from e\n",
        "\n",
        "test_preds[\"game_date\"] = pd.to_datetime(test_preds[\"game_date\"])\n",
        "test_preds[\"predicted_home_win_prob\"] = test_preds[\"predicted_home_win_prob\"].astype(float)\n",
        "test_preds[\"actual_home_win\"] = test_preds[\"actual_home_win\"].astype(int)\n",
        "\n",
        "print(f\"✓ Loaded {len(test_preds)} test games\")\n",
        "print(f\"✓ Test season: {test_preds['season'].unique()}\")\n",
        "print(f\"✓ Date range: {test_preds['game_date'].min().date()} to {test_preds['game_date'].max().date()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — VERIFY PREDICTION QUALITY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Verifying prediction quality\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss\n",
        "\n",
        "actual = test_preds[\"actual_home_win\"].values\n",
        "predicted_prob = test_preds[\"predicted_home_win_prob\"].values\n",
        "\n",
        "acc = accuracy_score(actual, predicted_prob > 0.5)\n",
        "logloss = log_loss(actual, predicted_prob)\n",
        "brier = brier_score_loss(actual, predicted_prob)\n",
        "\n",
        "print(f\"✓ Accuracy: {acc:.4f}\")\n",
        "print(f\"✓ Log Loss: {logloss:.4f}\")\n",
        "print(f\"✓ Brier Score: {brier:.4f}\")\n",
        "\n",
        "print(f\"\\nPrediction distribution:\")\n",
        "print(f\"  Mean: {predicted_prob.mean():.3f}\")\n",
        "print(f\"  Std: {predicted_prob.std():.3f}\")\n",
        "print(f\"  Min: {predicted_prob.min():.3f}\")\n",
        "print(f\"  Max: {predicted_prob.max():.3f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — MONTE CARLO SIMULATION (VECTORIZED)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Running Monte Carlo simulation\")\n",
        "print(f\"  Simulations: {N_SIMULATIONS:,}\")\n",
        "print(f\"  ⏳ This may take a few seconds...\")\n",
        "\n",
        "# Precompute indices for home/away teams\n",
        "teams = sorted(set(test_preds[\"home_team\"]).union(test_preds[\"away_team\"]))\n",
        "team_to_idx = {team: i for i, team in enumerate(teams)}\n",
        "n_teams = len(teams)\n",
        "n_games = len(test_preds)\n",
        "\n",
        "# Vectorized simulation\n",
        "sim_matrix = np.random.binomial(1, predicted_prob, size=(N_SIMULATIONS, n_games))\n",
        "team_wins_matrix = np.zeros((N_SIMULATIONS, n_teams), dtype=int)\n",
        "\n",
        "home_indices = test_preds[\"home_team\"].map(team_to_idx).values\n",
        "away_indices = test_preds[\"away_team\"].map(team_to_idx).values\n",
        "\n",
        "for g in range(n_games):\n",
        "    team_wins_matrix[:, home_indices[g]] += sim_matrix[:, g]\n",
        "    team_wins_matrix[:, away_indices[g]] += (1 - sim_matrix[:, g])\n",
        "\n",
        "# Aggregate results\n",
        "team_wins = {team: team_wins_matrix[:, i] for team, i in team_to_idx.items()}\n",
        "\n",
        "print(f\"✓ Simulation complete\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — AGGREGATE TEAM STATISTICS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Computing team statistics\")\n",
        "\n",
        "team_stats = pd.DataFrame([\n",
        "    {\n",
        "        \"team\": team,\n",
        "        \"expected_wins\": wins.mean(),\n",
        "        \"std_wins\": wins.std(),\n",
        "        \"min_wins\": wins.min(),\n",
        "        \"max_wins\": wins.max(),\n",
        "        \"p10\": np.percentile(wins, 10),\n",
        "        \"p90\": np.percentile(wins, 90)\n",
        "    }\n",
        "    for team, wins in team_wins.items()\n",
        "]).sort_values(\"expected_wins\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 teams by expected wins:\")\n",
        "print(team_stats.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nBottom 5 teams by expected wins:\")\n",
        "print(team_stats.tail(5).to_string(index=False))\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — COMPARE TO ACTUAL RESULTS (VECTORIZED)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Comparing simulated vs actual results\")\n",
        "\n",
        "home_wins = test_preds.groupby(\"home_team\")[\"actual_home_win\"].sum()\n",
        "away_wins = test_preds.groupby(\"away_team\")[\"actual_home_win\"].apply(lambda x: len(x) - x.sum())\n",
        "actual_wins = home_wins.add(away_wins, fill_value=0)\n",
        "\n",
        "team_stats[\"actual_wins\"] = team_stats[\"team\"].map(actual_wins)\n",
        "team_stats[\"prediction_error\"] = team_stats[\"expected_wins\"] - team_stats[\"actual_wins\"]\n",
        "\n",
        "mae = team_stats[\"prediction_error\"].abs().mean()\n",
        "rmse = np.sqrt((team_stats[\"prediction_error\"] ** 2).mean())\n",
        "\n",
        "print(f\"\\n✓ Prediction quality:\")\n",
        "print(f\"  Mean Absolute Error: {mae:.2f} wins\")\n",
        "print(f\"  Root Mean Squared Error: {rmse:.2f} wins\")\n",
        "\n",
        "print(\"\\nBiggest prediction errors:\")\n",
        "print(team_stats.nlargest(5, \"prediction_error\")[[\"team\", \"expected_wins\", \"actual_wins\", \"prediction_error\"]].to_string(index=False))\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — UPSET ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Analyzing upsets\")\n",
        "\n",
        "low_prob_games = test_preds[test_preds[\"predicted_home_win_prob\"] < 0.3]\n",
        "upsets = low_prob_games[low_prob_games[\"actual_home_win\"] == 1]\n",
        "upset_rate = len(upsets) / len(low_prob_games) if len(low_prob_games) > 0 else np.nan\n",
        "expected_upset_rate = low_prob_games[\"predicted_home_win_prob\"].mean() if len(low_prob_games) > 0 else np.nan\n",
        "\n",
        "print(f\"\\nUpset analysis (home win prob < 0.3):\")\n",
        "print(f\"  Total low-probability predictions: {len(low_prob_games)}\")\n",
        "print(f\"  Actual upsets: {len(upsets)}\")\n",
        "print(f\"  Upset rate: {upset_rate:.3f}\")\n",
        "print(f\"  Expected upset rate: {expected_upset_rate:.3f}\")\n",
        "print(f\"  Calibration: {'Good' if abs(upset_rate - expected_upset_rate) < 0.05 else 'Needs improvement'}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — VISUALIZATIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Creating visualizations\")\n",
        "\n",
        "# Scatter plot: Expected vs Actual Wins\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(team_stats[\"expected_wins\"], team_stats[\"actual_wins\"], alpha=0.6, s=100)\n",
        "plt.plot([20, 70], [20, 70], \"r--\", label=\"Perfect prediction\", linewidth=2)\n",
        "for _, row in team_stats.iterrows():\n",
        "    if abs(row[\"prediction_error\"]) > 5:\n",
        "        plt.annotate(row[\"team\"], (row[\"expected_wins\"], row[\"actual_wins\"]), fontsize=8, alpha=0.7)\n",
        "plt.xlabel(\"Expected Wins (Simulated)\", fontsize=12)\n",
        "plt.ylabel(\"Actual Wins\", fontsize=12)\n",
        "plt.title(\"Simulated vs Actual Season Performance\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/simulated_vs_actual.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "print(\"✓ Simulated vs actual plot saved\")\n",
        "\n",
        "# Win distribution for top 5 teams (interactive)\n",
        "top_5_teams = team_stats.head(5)[\"team\"].values\n",
        "fig = go.Figure()\n",
        "for team in top_5_teams:\n",
        "    fig.add_trace(go.Violin(y=team_wins[team], name=team, box_visible=True, meanline_visible=True))\n",
        "fig.update_layout(title=\"Win Distribution - Top 5 Teams (Monte Carlo)\", yaxis_title=\"Total Wins\", showlegend=True, height=600)\n",
        "fig.write_html(\"evaluation/win_distribution_top5.html\")\n",
        "print(\"✓ Win distribution plot saved (interactive HTML)\")\n",
        "\n",
        "# Season uncertainty\n",
        "plt.figure(figsize=(12, 8))\n",
        "team_stats_sorted = team_stats.sort_values(\"expected_wins\")\n",
        "y_pos = np.arange(len(team_stats_sorted))\n",
        "expected = team_stats_sorted[\"expected_wins\"].values\n",
        "p10 = team_stats_sorted[\"p10\"].values\n",
        "p90 = team_stats_sorted[\"p90\"].values\n",
        "plt.barh(y_pos, expected, alpha=0.6, label=\"Expected wins\")\n",
        "plt.errorbar(expected, y_pos, xerr=[expected - p10, p90 - expected], fmt=\"none\", ecolor=\"black\", alpha=0.5, capsize=3, label=\"10th-90th percentile\")\n",
        "plt.yticks(y_pos, team_stats_sorted[\"team\"], fontsize=8)\n",
        "plt.xlabel(\"Wins\", fontsize=12)\n",
        "plt.title(\"Simulated Season: Expected Wins with Uncertainty\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(axis=\"x\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/season_uncertainty.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "print(\"✓ Uncertainty plot saved\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — SAVE RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Saving simulation results\")\n",
        "\n",
        "results_path = save_checkpoint(team_stats, \"simulation_results.csv\", \"Monte Carlo simulation results per team\")\n",
        "print(f\"✓ Simulation results saved to {results_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MONTE CARLO SIMULATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n✓ Simulations run: {N_SIMULATIONS:,}\")\n",
        "print(f\"✓ Teams analyzed: {len(team_stats)}\")\n",
        "print(f\"✓ Mean absolute error: {mae:.2f} wins per team\")\n",
        "print(f\"✓ Prediction uncertainty: {team_stats['std_wins'].mean():.2f} wins (avg)\")\n",
        "print(\"\\n✓ Visualizations created:\")\n",
        "print(\"  • evaluation/simulated_vs_actual.png\")\n",
        "print(\"  • evaluation/win_distribution_top5.html\")\n",
        "print(\"  • evaluation/season_uncertainty.png\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROJECT COMPLETE!\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIrMzl5wl85n",
        "outputId": "6f3e4a7a-0fcf-4582-ce8b-cb031a97be88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "MONTE CARLO SEASON SIMULATION\n",
            "============================================================\n",
            "\n",
            "[1] Loading test predictions\n",
            "✓ Loaded: test_predictions_fixed.csv\n",
            "  Shape: (1230, 39)\n",
            "✓ Loaded 1230 test games\n",
            "✓ Test season: ['2023-24']\n",
            "✓ Date range: 2023-10-24 to 2024-04-14\n",
            "\n",
            "[2] Verifying prediction quality\n",
            "✓ Accuracy: 0.5976\n",
            "✓ Log Loss: 0.6693\n",
            "✓ Brier Score: 0.2382\n",
            "\n",
            "Prediction distribution:\n",
            "  Mean: 0.561\n",
            "  Std: 0.144\n",
            "  Min: 0.135\n",
            "  Max: 0.910\n",
            "\n",
            "[3] Running Monte Carlo simulation\n",
            "  Simulations: 10,000\n",
            "  ⏳ This may take a few seconds...\n",
            "✓ Simulation complete\n",
            "\n",
            "[4] Computing team statistics\n",
            "\n",
            "Top 10 teams by expected wins:\n",
            "team  expected_wins  std_wins  min_wins  max_wins    p10    p90\n",
            " BOS         48.482     4.272        33        65 43.000 54.000\n",
            " MIN         46.379     4.307        29        63 41.000 52.000\n",
            " OKC         45.740     4.294        28        64 40.000 51.000\n",
            " NYK         45.215     4.152        25        59 40.000 51.000\n",
            " NOP         44.804     4.252        27        60 39.000 50.000\n",
            " DEN         44.802     4.311        25        59 39.000 50.000\n",
            " ORL         43.981     4.276        26        58 39.000 49.000\n",
            " SAC         43.899     4.368        27        61 38.000 49.000\n",
            " MIL         43.712     4.257        28        60 38.000 49.000\n",
            " CLE         43.474     4.255        27        60 38.000 49.000\n",
            "\n",
            "Bottom 5 teams by expected wins:\n",
            "team  expected_wins  std_wins  min_wins  max_wins    p10    p90\n",
            " SAS         35.200     4.275        20        50 30.000 41.000\n",
            " CHA         34.831     4.315        18        53 29.000 40.000\n",
            " TOR         34.802     4.314        17        51 29.000 40.000\n",
            " WAS         34.682     4.302        18        52 29.000 40.000\n",
            " DET         33.774     4.236        17        50 28.000 39.000\n",
            "\n",
            "[5] Comparing simulated vs actual results\n",
            "\n",
            "✓ Prediction quality:\n",
            "  Mean Absolute Error: 8.11 wins\n",
            "  Root Mean Squared Error: 9.57 wins\n",
            "\n",
            "Biggest prediction errors:\n",
            "team  expected_wins  actual_wins  prediction_error\n",
            " DET         33.774           14            19.774\n",
            " WAS         34.682           15            19.682\n",
            " POR         35.790           21            14.790\n",
            " CHA         34.831           21            13.831\n",
            " SAS         35.200           22            13.200\n",
            "\n",
            "[6] Analyzing upsets\n",
            "\n",
            "Upset analysis (home win prob < 0.3):\n",
            "  Total low-probability predictions: 75\n",
            "  Actual upsets: 26\n",
            "  Upset rate: 0.347\n",
            "  Expected upset rate: 0.240\n",
            "  Calibration: Needs improvement\n",
            "\n",
            "[7] Creating visualizations\n",
            "✓ Simulated vs actual plot saved\n",
            "✓ Win distribution plot saved (interactive HTML)\n",
            "✓ Uncertainty plot saved\n",
            "\n",
            "[8] Saving simulation results\n",
            "✓ [2026-01-06 00:56:59] Saved: simulation_results.csv\n",
            "  Monte Carlo simulation results per team\n",
            "  Shape: (30, 9)\n",
            "✓ Simulation results saved to /content/drive/MyDrive/nba_predictor/data/processed/simulation_results.csv\n",
            "\n",
            "============================================================\n",
            "MONTE CARLO SIMULATION COMPLETE\n",
            "============================================================\n",
            "\n",
            "✓ Simulations run: 10,000\n",
            "✓ Teams analyzed: 30\n",
            "✓ Mean absolute error: 8.11 wins per team\n",
            "✓ Prediction uncertainty: 4.30 wins (avg)\n",
            "\n",
            "✓ Visualizations created:\n",
            "  • evaluation/simulated_vs_actual.png\n",
            "  • evaluation/win_distribution_top5.html\n",
            "  • evaluation/season_uncertainty.png\n",
            "\n",
            "============================================================\n",
            "PROJECT COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "Stage 6 IMPROVEMENTS - Quick Wins\n",
        "\n",
        "Adds:\n",
        "1. L10 rolling window (more stable than L5)\n",
        "2. Exponentially weighted rolling stats (recent games matter more)\n",
        "3. Days since trade deadline feature\n",
        "4. Ensemble model (Logistic Regression + XGBoost)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# =============================================================================\n",
        "# SETUP DIRECTORIES\n",
        "# =============================================================================\n",
        "\n",
        "Path(\"evaluation\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1: ADVANCED FEATURES & ENSEMBLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "TRADE_DEADLINES = {\n",
        "    \"2021-22\": \"2022-02-10\",\n",
        "    \"2022-23\": \"2023-02-09\",\n",
        "    \"2023-24\": \"2024-02-08\"\n",
        "}\n",
        "\n",
        "DECAY_ALPHA = 0.95  # Exponential decay weight (0.95 = 5% decay per game back)\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD EXISTING DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading team game log\")\n",
        "\n",
        "try:\n",
        "    team_log = load_checkpoint(\"team_rolling_stats_cache.csv\")\n",
        "    assert team_log is not None\n",
        "except Exception as e:\n",
        "    raise FileNotFoundError(\"team_rolling_stats_cache.csv not found.\") from e\n",
        "\n",
        "team_log[\"game_date\"] = pd.to_datetime(team_log[\"game_date\"])\n",
        "\n",
        "# Ensure numeric types\n",
        "team_log[\"pts_scored\"] = team_log[\"pts_scored\"].astype(float)\n",
        "team_log[\"pts_allowed\"] = team_log[\"pts_allowed\"].astype(float)\n",
        "team_log[\"net_rating\"] = team_log[\"net_rating\"].astype(float)\n",
        "team_log[\"won\"] = team_log[\"won\"].astype(int)\n",
        "\n",
        "print(f\"✓ Loaded {len(team_log)} team-game rows\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — L10 ROLLING WINDOW\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Adding L10 rolling window\")\n",
        "\n",
        "def add_l10_window(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    grouped = df.groupby([\"team\", \"season\"])\n",
        "    df = df.copy()\n",
        "\n",
        "    df[\"pts_scored_L10\"] = grouped[\"pts_scored\"].shift(1).rolling(10, min_periods=1).mean()\n",
        "    df[\"pts_allowed_L10\"] = grouped[\"pts_allowed\"].shift(1).rolling(10, min_periods=1).mean()\n",
        "    df[\"net_rating_L10\"] = grouped[\"net_rating\"].shift(1).rolling(10, min_periods=1).mean()\n",
        "    df[\"win_rate_L10\"] = grouped[\"won\"].shift(1).rolling(10, min_periods=1).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "team_log = add_l10_window(team_log)\n",
        "print(\"✓ L10 window added\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — EXPONENTIALLY WEIGHTED STATS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Adding exponentially weighted rolling stats\")\n",
        "\n",
        "def add_ew_stats(\n",
        "    df: pd.DataFrame,\n",
        "    alpha: float = 0.95,\n",
        "    window: int = 10\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add exponentially weighted rolling stats (EWMA),\n",
        "    shifted by 1 game to prevent leakage.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    ew_frames = []\n",
        "\n",
        "    for (team, season), group in df.groupby([\"team\", \"season\"]):\n",
        "        group = group.sort_values(\"game_date\").reset_index(drop=True)\n",
        "\n",
        "        # Shift to avoid leakage\n",
        "        shifted = group[[\"net_rating\", \"pts_scored\", \"pts_allowed\"]].shift(1)\n",
        "\n",
        "        # EWMA\n",
        "        ew = shifted.ewm(alpha=1 - alpha, adjust=False).mean()\n",
        "\n",
        "        # Optional: cap influence to last N games\n",
        "        if window is not None:\n",
        "            ew = ew.rolling(window, min_periods=1).mean()\n",
        "\n",
        "        group[\"net_rating_EW10\"] = ew[\"net_rating\"]\n",
        "        group[\"pts_scored_EW10\"] = ew[\"pts_scored\"]\n",
        "        group[\"pts_allowed_EW10\"] = ew[\"pts_allowed\"]\n",
        "\n",
        "        ew_frames.append(group)\n",
        "\n",
        "    return pd.concat(ew_frames, ignore_index=True)\n",
        "\n",
        "\n",
        "team_log = add_ew_stats(team_log, alpha=DECAY_ALPHA, window=10)\n",
        "print(\"✓ Exponentially weighted stats added\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — DAYS SINCE TRADE DEADLINE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Adding days since trade deadline feature\")\n",
        "\n",
        "def add_trade_deadline(df: pd.DataFrame, deadlines: dict) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    deadlines_dt = {s: pd.to_datetime(d) for s, d in deadlines.items()}\n",
        "\n",
        "    df[\"trade_deadline\"] = df[\"season\"].map(deadlines_dt)\n",
        "    df[\"days_since_deadline\"] = (df[\"game_date\"] - df[\"trade_deadline\"]).dt.days\n",
        "    df[\"days_since_deadline\"] = df[\"days_since_deadline\"].clip(-60, 60)\n",
        "    df[\"is_post_deadline\"] = (df[\"days_since_deadline\"] > 0).astype(int)\n",
        "    return df\n",
        "\n",
        "team_log = add_trade_deadline(team_log, TRADE_DEADLINES)\n",
        "print(\"✓ Trade deadline feature added\")\n",
        "print(f\"  Games before deadline: {(team_log['days_since_deadline'] < 0).sum()}\")\n",
        "print(f\"  Games after deadline: {(team_log['days_since_deadline'] > 0).sum()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — SAVE ENHANCED CACHE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Saving enhanced rolling stats cache\")\n",
        "\n",
        "cache_path = save_checkpoint(\n",
        "    team_log,\n",
        "    \"team_rolling_stats_enhanced.csv\",\n",
        "    \"Enhanced cache with L10, EW stats, and trade deadline\"\n",
        ")\n",
        "print(f\"✓ Enhanced cache saved: {cache_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — MERGE TO GAME LEVEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Merging enhanced features to game level\")\n",
        "\n",
        "games = load_checkpoint(\"games_with_context.csv\")\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "\n",
        "merge_cols = [\n",
        "    \"game_id\", \"team\",\n",
        "    \"net_rating_L10\", \"pts_scored_L10\", \"pts_allowed_L10\", \"win_rate_L10\",\n",
        "    \"net_rating_EW10\", \"pts_scored_EW10\", \"pts_allowed_EW10\",\n",
        "    \"days_since_deadline\", \"is_post_deadline\"\n",
        "]\n",
        "\n",
        "# Home merge\n",
        "games = games.merge(\n",
        "    team_log[merge_cols],\n",
        "    left_on=[\"game_id\", \"home_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\")\n",
        "\n",
        "games = games.rename(columns={\n",
        "    \"net_rating_L10\": \"home_net_L10\",\n",
        "    \"pts_scored_L10\": \"home_pts_L10\",\n",
        "    \"pts_allowed_L10\": \"home_pa_L10\",\n",
        "    \"win_rate_L10\": \"home_winpct_L10\",\n",
        "    \"net_rating_EW10\": \"home_net_EW10\",\n",
        "    \"pts_scored_EW10\": \"home_pts_EW10\",\n",
        "    \"pts_allowed_EW10\": \"home_pa_EW10\",\n",
        "    \"days_since_deadline\": \"home_days_since_deadline\",\n",
        "    \"is_post_deadline\": \"home_post_deadline\"\n",
        "})\n",
        "\n",
        "# Away merge\n",
        "games = games.merge(\n",
        "    team_log[merge_cols],\n",
        "    left_on=[\"game_id\", \"away_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\")\n",
        "\n",
        "games = games.rename(columns={\n",
        "    \"net_rating_L10\": \"away_net_L10\",\n",
        "    \"pts_scored_L10\": \"away_pts_L10\",\n",
        "    \"pts_allowed_L10\": \"away_pa_L10\",\n",
        "    \"win_rate_L10\": \"away_winpct_L10\",\n",
        "    \"net_rating_EW10\": \"away_net_EW10\",\n",
        "    \"pts_scored_EW10\": \"away_pts_EW10\",\n",
        "    \"pts_allowed_EW10\": \"away_pa_EW10\",\n",
        "    \"days_since_deadline\": \"away_days_since_deadline\",\n",
        "    \"is_post_deadline\": \"away_post_deadline\"\n",
        "})\n",
        "\n",
        "print(\"✓ Enhanced features merged to game level\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — NORMALIZE FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Normalizing new features within seasons\")\n",
        "\n",
        "def normalize_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    cols = [\n",
        "        \"home_net_L10\", \"home_pts_L10\", \"home_pa_L10\",\n",
        "        \"away_net_L10\", \"away_pts_L10\", \"away_pa_L10\",\n",
        "        \"home_net_EW10\", \"home_pts_EW10\", \"home_pa_EW10\",\n",
        "        \"away_net_EW10\", \"away_pts_EW10\", \"away_pa_EW10\"\n",
        "    ]\n",
        "    for col in cols:\n",
        "        df[f\"{col}_z\"] = df.groupby(\"season\")[col].transform(\n",
        "            lambda x: (x - x.mean()) / x.std(ddof=0) if x.std(ddof=0) != 0 else 0\n",
        "        )\n",
        "    return df\n",
        "\n",
        "games = normalize_features(games)\n",
        "print(\"✓ New features normalized\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — CREATE MATCHUP FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Creating enhanced matchup features\")\n",
        "\n",
        "games[\"net_diff_L10\"] = games[\"home_net_L10_z\"] - games[\"away_net_L10_z\"]\n",
        "games[\"off_vs_def_L10\"] = games[\"home_pts_L10_z\"] - games[\"away_pa_L10_z\"]\n",
        "games[\"winpct_diff_L10\"] = games[\"home_winpct_L10\"] - games[\"away_winpct_L10\"]\n",
        "\n",
        "games[\"net_diff_EW10\"] = games[\"home_net_EW10_z\"] - games[\"away_net_EW10_z\"]\n",
        "games[\"off_vs_def_EW10\"] = games[\"home_pts_EW10_z\"] - games[\"away_pa_EW10_z\"]\n",
        "\n",
        "games[\"deadline_advantage\"] = games[\"home_days_since_deadline\"] - games[\"away_days_since_deadline\"]\n",
        "games[\"both_post_deadline\"] = ((games[\"home_post_deadline\"] == 1) & (games[\"away_post_deadline\"] == 1)).astype(int)\n",
        "\n",
        "print(\"✓ Enhanced matchup features created\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8 — SAVE ENHANCED DATASET\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[9] Saving enhanced game-level dataset\")\n",
        "\n",
        "output_path = save_checkpoint(\n",
        "    games,\n",
        "    \"games_with_enhanced_features.csv\",\n",
        "    \"Games with L10, EW, and trade deadline features\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Enhanced dataset saved: {output_path}\")\n",
        "print(f\"  Total features: {len(games.columns)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1 FEATURES COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n✓ New features added:\")\n",
        "print(\"  • L10 rolling window (10-game averages)\")\n",
        "print(\"  • Exponentially weighted stats (recent games weighted higher)\")\n",
        "print(\"  • Days since trade deadline\")\n",
        "print(\"  • Post-deadline binary indicator\")\n",
        "print(\"  • Enhanced matchup differentials\")\n",
        "print(f\"\\n✓ Total games: {len(games)}\")\n",
        "print(f\"✓ Total features: {len(games.columns)}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NEXT: Train models with enhanced features\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqZ2tnInd4ht",
        "outputId": "157e1c68-dee4-46d6-ced4-fa6416fa28ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PHASE 1: ADVANCED FEATURES & ENSEMBLE\n",
            "============================================================\n",
            "\n",
            "[1] Loading team game log\n",
            "✓ Loaded: team_rolling_stats_cache.csv\n",
            "  Shape: (7380, 20)\n",
            "✓ Loaded 7380 team-game rows\n",
            "\n",
            "[2] Adding L10 rolling window\n",
            "✓ L10 window added\n",
            "\n",
            "[3] Adding exponentially weighted rolling stats\n",
            "✓ Exponentially weighted stats added\n",
            "\n",
            "[4] Adding days since trade deadline feature\n",
            "✓ Trade deadline feature added\n",
            "  Games before deadline: 4826\n",
            "  Games after deadline: 2514\n",
            "\n",
            "[5] Saving enhanced rolling stats cache\n",
            "✓ [2026-01-06 00:57:01] Saved: team_rolling_stats_enhanced.csv\n",
            "  Enhanced cache with L10, EW stats, and trade deadline\n",
            "  Shape: (7380, 26)\n",
            "✓ Enhanced cache saved: /content/drive/MyDrive/nba_predictor/data/processed/team_rolling_stats_enhanced.csv\n",
            "\n",
            "[6] Merging enhanced features to game level\n",
            "✓ Loaded: games_with_context.csv\n",
            "  Shape: (3690, 18)\n",
            "✓ Enhanced features merged to game level\n",
            "\n",
            "[7] Normalizing new features within seasons\n",
            "✓ New features normalized\n",
            "\n",
            "[8] Creating enhanced matchup features\n",
            "✓ Enhanced matchup features created\n",
            "\n",
            "[9] Saving enhanced game-level dataset\n",
            "✓ [2026-01-06 00:57:02] Saved: games_with_enhanced_features.csv\n",
            "  Games with L10, EW, and trade deadline features\n",
            "  Shape: (3690, 55)\n",
            "✓ Enhanced dataset saved: /content/drive/MyDrive/nba_predictor/data/processed/games_with_enhanced_features.csv\n",
            "  Total features: 55\n",
            "\n",
            "============================================================\n",
            "PHASE 1 FEATURES COMPLETE\n",
            "============================================================\n",
            "\n",
            "✓ New features added:\n",
            "  • L10 rolling window (10-game averages)\n",
            "  • Exponentially weighted stats (recent games weighted higher)\n",
            "  • Days since trade deadline\n",
            "  • Post-deadline binary indicator\n",
            "  • Enhanced matchup differentials\n",
            "\n",
            "✓ Total games: 3690\n",
            "✓ Total features: 55\n",
            "\n",
            "============================================================\n",
            "NEXT: Train models with enhanced features\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "Stage 7 — ENSEMBLE MODEL (PRODUCTION, FIXED)\n",
        "\n",
        "Ensemble of:\n",
        "- Logistic Regression (scaled)\n",
        "- XGBoost (native API, safe early stopping)\n",
        "\n",
        "Trains ONLY on enhanced feature set (L10 + EW10 + Deadline).\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# HARD SAFETY GUARANTEES (DO NOT MOVE)\n",
        "# =============================================================================\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Path(\"evaluation\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# =============================================================================\n",
        "# IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "from scipy.optimize import minimize\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD DATA (FAIL LOUDLY)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ENSEMBLE MODEL WITH ENHANCED FEATURES (PRODUCTION)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "games = load_checkpoint(\"games_with_enhanced_features.csv\")\n",
        "if games is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"games_with_enhanced_features.csv missing. \"\n",
        "        \"Run Phase 1 feature generation first.\"\n",
        "    )\n",
        "\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "print(f\"✓ Loaded {len(games)} games\")\n",
        "\n",
        "# =============================================================================\n",
        "# FEATURE DEFINITIONS (ENHANCED ONLY)\n",
        "# =============================================================================\n",
        "\n",
        "context_features = [\n",
        "    \"home_rest_days\", \"away_rest_days\", \"rest_advantage\",\n",
        "    \"home_b2b\", \"away_b2b\", \"both_b2b\"\n",
        "]\n",
        "\n",
        "l10_features = [\n",
        "    \"home_net_L10_z\", \"away_net_L10_z\",\n",
        "    \"home_pts_L10_z\", \"away_pts_L10_z\",\n",
        "    \"home_pa_L10_z\", \"away_pa_L10_z\",\n",
        "    \"home_winpct_L10\", \"away_winpct_L10\",\n",
        "    \"net_diff_L10\", \"off_vs_def_L10\", \"winpct_diff_L10\"\n",
        "]\n",
        "\n",
        "ew_features = [\n",
        "    \"home_net_EW10_z\", \"away_net_EW10_z\",\n",
        "    \"home_pts_EW10_z\", \"away_pts_EW10_z\",\n",
        "    \"home_pa_EW10_z\", \"away_pa_EW10_z\",\n",
        "    \"net_diff_EW10\", \"off_vs_def_EW10\"\n",
        "]\n",
        "\n",
        "deadline_features = [\n",
        "    \"home_days_since_deadline\", \"away_days_since_deadline\",\n",
        "    \"deadline_advantage\", \"both_post_deadline\"\n",
        "]\n",
        "\n",
        "all_features = (\n",
        "    context_features\n",
        "    + l10_features\n",
        "    + ew_features\n",
        "    + deadline_features\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# FEATURE CONTRACT VALIDATION (CRITICAL)\n",
        "# =============================================================================\n",
        "\n",
        "missing = [f for f in all_features if f not in games.columns]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Missing features in dataset: {missing}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TYPE SAFETY + IMPUTATION\n",
        "# =============================================================================\n",
        "\n",
        "y = games[\"home_win\"].astype(int)\n",
        "\n",
        "X = (\n",
        "    games[all_features]\n",
        "    .apply(pd.to_numeric, errors=\"coerce\")\n",
        "    .fillna(games[all_features].mean())\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# TIME-SAFE TRAIN / VAL / TEST SPLIT\n",
        "# =============================================================================\n",
        "\n",
        "TRAIN_SEASONS = [\"2021-22\", \"2022-23\"]\n",
        "TEST_SEASON = \"2023-24\"\n",
        "\n",
        "train_df = games[games[\"season\"].isin(TRAIN_SEASONS)].sort_values(\"game_date\")\n",
        "test_df = games[games[\"season\"] == TEST_SEASON].sort_values(\"game_date\")\n",
        "\n",
        "X_train_full = X.loc[train_df.index].reset_index(drop=True)\n",
        "y_train_full = y.loc[train_df.index].reset_index(drop=True)\n",
        "\n",
        "X_test = X.loc[test_df.index].reset_index(drop=True)\n",
        "y_test = y.loc[test_df.index].reset_index(drop=True)\n",
        "\n",
        "val_size = int(len(X_train_full) * 0.1)\n",
        "\n",
        "X_train = X_train_full.iloc[:-val_size]\n",
        "y_train = y_train_full.iloc[:-val_size]\n",
        "X_val = X_train_full.iloc[-val_size:]\n",
        "y_val = y_train_full.iloc[-val_size:]\n",
        "\n",
        "print(f\"✓ Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# LOGISTIC REGRESSION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Training Logistic Regression\")\n",
        "\n",
        "lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        solver=\"lbfgs\",\n",
        "        random_state=RANDOM_SEED\n",
        "    ))\n",
        "])\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "lr_val = lr.predict_proba(X_val)[:, 1]\n",
        "lr_test = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# =============================================================================\n",
        "# XGBOOST (NATIVE API)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Training XGBoost\")\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"logloss\",\n",
        "    \"max_depth\": 4,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"seed\": RANDOM_SEED,\n",
        "    \"tree_method\": \"hist\",\n",
        "}\n",
        "\n",
        "model_xgb = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=500,\n",
        "    evals=[(dval, \"val\")],\n",
        "    early_stopping_rounds=30,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "xgb_val = model_xgb.predict(dval)\n",
        "xgb_test = model_xgb.predict(dtest)\n",
        "\n",
        "# =============================================================================\n",
        "# ENSEMBLE — WEIGHT OPTIMIZATION\n",
        "# =============================================================================\n",
        "\n",
        "def ensemble_logloss(w):\n",
        "    p = w[0] * lr_val + w[1] * xgb_val\n",
        "    p = np.clip(p, 1e-15, 1 - 1e-15)\n",
        "    return log_loss(y_val, p)\n",
        "\n",
        "result = minimize(\n",
        "    ensemble_logloss,\n",
        "    x0=[0.5, 0.5],\n",
        "    bounds=[(0, 1), (0, 1)],\n",
        "    constraints={\"type\": \"eq\", \"fun\": lambda w: w.sum() - 1}\n",
        ")\n",
        "\n",
        "weights = result.x if result.success else np.array([0.5, 0.5])\n",
        "\n",
        "ensemble_test = weights[0] * lr_test + weights[1] * xgb_test\n",
        "\n",
        "# =============================================================================\n",
        "# CALIBRATION PLOT\n",
        "# =============================================================================\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "\n",
        "for probs, label in [\n",
        "    (lr_test, \"Logistic Regression\"),\n",
        "    (xgb_test, \"XGBoost\"),\n",
        "    (ensemble_test, \"Ensemble\"),\n",
        "]:\n",
        "    t, p = calibration_curve(y_test, probs, n_bins=10)\n",
        "    plt.plot(p, t, marker=\"o\", label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/calibration_models.png\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# =============================================================================\n",
        "# SAVE MODELS\n",
        "# =============================================================================\n",
        "\n",
        "with open(\"models/logistic_regression_enhanced.pkl\", \"wb\") as f:\n",
        "    pickle.dump(lr, f)\n",
        "\n",
        "model_xgb.save_model(\"models/xgboost_enhanced.json\")\n",
        "\n",
        "with open(\"models/ensemble_config.json\", \"w\") as f:\n",
        "    json.dump(\n",
        "        {\"weights\": weights.tolist(), \"seed\": RANDOM_SEED},\n",
        "        f,\n",
        "        indent=2\n",
        "    )\n",
        "\n",
        "print(\"✓ Production ensemble training complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mDV7OAmeeHM",
        "outputId": "2420e0bf-5f9d-4041-f922-7e27605c4c72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ENSEMBLE MODEL WITH ENHANCED FEATURES (PRODUCTION)\n",
            "============================================================\n",
            "✓ Loaded: games_with_enhanced_features.csv\n",
            "  Shape: (3690, 55)\n",
            "✓ Loaded 3690 games\n",
            "✓ Train: 2214 | Val: 246 | Test: 1230\n",
            "\n",
            "[2] Training Logistic Regression\n",
            "\n",
            "[3] Training XGBoost\n",
            "✓ Production ensemble training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "PHASE 2 — HISTORICAL DATA EXPANSION\n",
        "\n",
        "Pulls 10 seasons of NBA data: 2015-16 through 2024-25\n",
        "(Note: 2024-25 is current season, may be incomplete)\n",
        "\n",
        "Production features:\n",
        "- Intelligent retry with exponential backoff\n",
        "- Progress tracking with ETA\n",
        "- Checkpoint saves after each season\n",
        "- Handles API rate limits gracefully\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import random\n",
        "from typing import List, Optional\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "from nba_api.stats.static import teams\n",
        "from requests.exceptions import Timeout, ConnectionError\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 2: HISTORICAL DATA COLLECTION (2015-2024)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# All seasons from 2015-16 to 2023-24\n",
        "HISTORICAL_SEASONS = [\n",
        "    \"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\", \"2019-20\",  # 5 new seasons\n",
        "    \"2020-21\", \"2021-22\", \"2022-23\", \"2023-24\"              # Already have these\n",
        "]\n",
        "\n",
        "# API settings\n",
        "SLEEP_RANGE = (2.0, 4.0)  # Longer delays for historical pulls\n",
        "MAX_RETRIES = 5\n",
        "CHECKPOINT_FREQUENCY = 1  # Save after each season\n",
        "\n",
        "print(f\"\\n✓ Configuration:\")\n",
        "print(f\"  Seasons to pull: {len(HISTORICAL_SEASONS)}\")\n",
        "print(f\"  Date range: {HISTORICAL_SEASONS[0]} to {HISTORICAL_SEASONS[-1]}\")\n",
        "print(f\"  Sleep range: {SLEEP_RANGE[0]}-{SLEEP_RANGE[1]} seconds\")\n",
        "print(f\"  Max retries: {MAX_RETRIES}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — LOCK TEAM IDS (WITH HISTORICAL AWARENESS)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Locking team identifiers\")\n",
        "\n",
        "nba_teams = teams.get_teams()\n",
        "TEAM_ID_TO_ABBR = {t[\"id\"]: t[\"abbreviation\"] for t in nba_teams}\n",
        "\n",
        "# Note: Some franchises changed names/cities\n",
        "# - Charlotte Bobcats → Charlotte Hornets (2014)\n",
        "# - New Jersey Nets → Brooklyn Nets (2012)\n",
        "# - Seattle SuperSonics → Oklahoma City Thunder (2008)\n",
        "# nba_api handles these transitions automatically\n",
        "\n",
        "print(f\"✓ Locked {len(TEAM_ID_TO_ABBR)} team identifiers\")\n",
        "\n",
        "# Special handling for historical franchises\n",
        "HISTORICAL_TEAM_NOTES = {\n",
        "    \"CHA\": \"Charlotte became Hornets in 2014-15 (from Bobcats)\",\n",
        "}\n",
        "\n",
        "print(\"\\n  Historical notes:\")\n",
        "for abbr, note in HISTORICAL_TEAM_NOTES.items():\n",
        "    print(f\"    {abbr}: {note}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — SMART API PULL WITH RETRY LOGIC\n",
        "# =============================================================================\n",
        "\n",
        "def pull_season_games(\n",
        "    season: str,\n",
        "    retry_delay_multiplier: float = 1.5\n",
        ") -> Optional[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Pull raw team-game rows with intelligent retry + backoff.\n",
        "\n",
        "    Args:\n",
        "        season: Season string (e.g., \"2015-16\")\n",
        "        retry_delay_multiplier: Exponential backoff multiplier\n",
        "\n",
        "    Returns:\n",
        "        DataFrame of team-game rows, or None if all retries fail\n",
        "    \"\"\"\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            print(f\"    Attempt {attempt}/{MAX_RETRIES}...\", end=\" \")\n",
        "\n",
        "            finder = leaguegamefinder.LeagueGameFinder(\n",
        "                season_nullable=season,\n",
        "                league_id_nullable=\"00\",\n",
        "                season_type_nullable=\"Regular Season\",\n",
        "            )\n",
        "\n",
        "            df = finder.get_data_frames()[0]\n",
        "\n",
        "            # Lock team abbreviations immediately\n",
        "            df[\"team_abbr\"] = df[\"TEAM_ID\"].map(TEAM_ID_TO_ABBR)\n",
        "            df[\"season\"] = season\n",
        "\n",
        "            # Validate\n",
        "            assert df[\"team_abbr\"].notna().all(), \"Missing team abbreviations\"\n",
        "            assert len(df) > 2000, f\"Too few rows: {len(df)}\"\n",
        "\n",
        "            print(f\"✓ {len(df)} rows\")\n",
        "\n",
        "            # Respectful sleep (longer for historical data)\n",
        "            sleep_time = random.uniform(*SLEEP_RANGE)\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except (Timeout, ConnectionError) as e:\n",
        "            wait_time = SLEEP_RANGE[1] * (retry_delay_multiplier ** attempt)\n",
        "            print(f\"✗ Network error. Waiting {wait_time:.1f}s...\")\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "        except AssertionError as e:\n",
        "            print(f\"✗ Data quality issue: {e}\")\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Unexpected error: {type(e).__name__}\")\n",
        "            if attempt < MAX_RETRIES:\n",
        "                time.sleep(SLEEP_RANGE[1] * attempt)\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    print(f\"    ✗ All {MAX_RETRIES} attempts failed\")\n",
        "    return None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — PROGRESSIVE COLLECTION WITH CHECKPOINTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Pulling historical game data\")\n",
        "print(\"  ⏳ This will take 5-10 minutes (10 seasons × ~30 seconds each)\")\n",
        "print()\n",
        "\n",
        "start_time = datetime.now()\n",
        "successful_seasons = []\n",
        "failed_seasons = []\n",
        "all_team_games = []\n",
        "\n",
        "for idx, season in enumerate(HISTORICAL_SEASONS, 1):\n",
        "    print(f\"  [{idx}/{len(HISTORICAL_SEASONS)}] Pulling {season}...\")\n",
        "\n",
        "    df = pull_season_games(season)\n",
        "\n",
        "    if df is not None:\n",
        "        all_team_games.append(df)\n",
        "        successful_seasons.append(season)\n",
        "\n",
        "        # Checkpoint after each season\n",
        "        if idx % CHECKPOINT_FREQUENCY == 0:\n",
        "            checkpoint_df = pd.concat(all_team_games, ignore_index=True)\n",
        "            checkpoint_path = f\"data/raw/checkpoint_after_{season.replace('-', '_')}.csv\"\n",
        "            checkpoint_df.to_csv(checkpoint_path, index=False)\n",
        "            print(f\"    💾 Checkpoint saved: {len(checkpoint_df)} total rows\")\n",
        "    else:\n",
        "        failed_seasons.append(season)\n",
        "        print(f\"    ⚠ Season {season} failed - continuing...\")\n",
        "\n",
        "    # Progress estimate\n",
        "    elapsed = (datetime.now() - start_time).total_seconds()\n",
        "    avg_time_per_season = elapsed / idx\n",
        "    remaining_seasons = len(HISTORICAL_SEASONS) - idx\n",
        "    eta_seconds = remaining_seasons * avg_time_per_season\n",
        "    eta_minutes = eta_seconds / 60\n",
        "\n",
        "    if idx < len(HISTORICAL_SEASONS):\n",
        "        print(f\"    ⏱ ETA: {eta_minutes:.1f} minutes remaining\")\n",
        "    print()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — CONSOLIDATE AND VALIDATE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Consolidating results\")\n",
        "\n",
        "if len(all_team_games) == 0:\n",
        "    print(\"✗ CRITICAL: No data collected. Check API connection.\")\n",
        "    raise RuntimeError(\"Data collection failed completely\")\n",
        "\n",
        "raw_games = pd.concat(all_team_games, ignore_index=True)\n",
        "\n",
        "print(f\"✓ Collection complete!\")\n",
        "print(f\"  Successful: {len(successful_seasons)} seasons\")\n",
        "print(f\"  Failed: {len(failed_seasons)} seasons\")\n",
        "print(f\"  Total team-game rows: {len(raw_games):,}\")\n",
        "\n",
        "if failed_seasons:\n",
        "    print(f\"\\n⚠ Failed seasons: {', '.join(failed_seasons)}\")\n",
        "    print(\"  Re-run this script to retry failed seasons\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — DATA QUALITY CHECKS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Running data quality checks\")\n",
        "\n",
        "# Check 1: Expected games per season\n",
        "games_per_season = raw_games.groupby(\"season\").size()\n",
        "print(\"\\nTeam-game rows per season:\")\n",
        "for season, count in games_per_season.items():\n",
        "    expected = 2460  # 30 teams × 82 games\n",
        "    status = \"✓\" if 2300 < count < 2600 else \"⚠\"\n",
        "    print(f\"  {status} {season}: {count:,} rows (expected ~{expected:,})\")\n",
        "\n",
        "# Check 2: Missing team abbreviations\n",
        "missing_abbr = raw_games[\"team_abbr\"].isna().sum()\n",
        "if missing_abbr > 0:\n",
        "    print(f\"\\n⚠ WARNING: {missing_abbr} rows missing team abbreviations\")\n",
        "else:\n",
        "    print(\"\\n✓ All rows have team abbreviations\")\n",
        "\n",
        "# Check 3: Date range\n",
        "raw_games[\"GAME_DATE\"] = pd.to_datetime(raw_games[\"GAME_DATE\"])\n",
        "date_range = (raw_games[\"GAME_DATE\"].min(), raw_games[\"GAME_DATE\"].max())\n",
        "print(f\"\\n✓ Date range: {date_range[0].date()} to {date_range[1].date()}\")\n",
        "\n",
        "# Check 4: Unique games\n",
        "n_unique_games = raw_games[\"GAME_ID\"].nunique()\n",
        "print(f\"✓ Unique games: {n_unique_games:,}\")\n",
        "print(f\"  Expected team-game rows: {n_unique_games * 2:,}\")\n",
        "print(f\"  Actual team-game rows: {len(raw_games):,}\")\n",
        "\n",
        "if abs(len(raw_games) - n_unique_games * 2) > 10:\n",
        "    print(\"  ⚠ Row count mismatch - possible data quality issue\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — SAVE RAW HISTORICAL DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Saving raw historical data\")\n",
        "\n",
        "raw_filepath = save_checkpoint(\n",
        "    raw_games,\n",
        "    \"raw_games_historical_2015_2024.csv\",\n",
        "    \"Historical team-game data (2015-2024)\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Raw data saved: {raw_filepath}\")\n",
        "print(f\"  Rows: {len(raw_games):,}\")\n",
        "print(f\"  Columns: {len(raw_games.columns)}\")\n",
        "print(f\"  Size: {raw_games.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — TRANSFORM TO GAME LEVEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Transforming to game-level format\")\n",
        "\n",
        "def transform_historical_to_game_level(raw_games: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Transform team-game rows to game-level rows.\n",
        "    One row per game with home/away split.\n",
        "    \"\"\"\n",
        "    # Identify home vs away\n",
        "    raw_games[\"is_home\"] = raw_games[\"MATCHUP\"].str.contains(\"vs.\", na=False)\n",
        "\n",
        "    home = raw_games[raw_games[\"is_home\"]].copy()\n",
        "    away = raw_games[~raw_games[\"is_home\"]].copy()\n",
        "\n",
        "    print(f\"  Home rows: {len(home):,}\")\n",
        "    print(f\"  Away rows: {len(away):,}\")\n",
        "\n",
        "    # Merge\n",
        "    games = home.merge(\n",
        "        away,\n",
        "        on=[\"GAME_ID\", \"GAME_DATE\", \"season\"],\n",
        "        suffixes=(\"_home\", \"_away\"),\n",
        "        validate=\"one_to_one\"\n",
        "    )\n",
        "\n",
        "    print(f\"  Merged games: {len(games):,}\")\n",
        "\n",
        "    # Clean schema\n",
        "    games = games.rename(columns={\n",
        "        \"GAME_ID\": \"game_id\",\n",
        "        \"GAME_DATE\": \"game_date\",\n",
        "        \"TEAM_ID_home\": \"home_team_id\",\n",
        "        \"TEAM_ID_away\": \"away_team_id\",\n",
        "        \"team_abbr_home\": \"home_team\",\n",
        "        \"team_abbr_away\": \"away_team\",\n",
        "        \"PTS_home\": \"home_score\",\n",
        "        \"PTS_away\": \"away_score\",\n",
        "    })\n",
        "\n",
        "    # Create target\n",
        "    games[\"home_win\"] = (games[\"home_score\"] > games[\"away_score\"]).astype(int)\n",
        "\n",
        "    # Sort chronologically\n",
        "    games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "    games = games.sort_values(\"game_date\").reset_index(drop=True)\n",
        "\n",
        "    # Select essential columns\n",
        "    essential_cols = [\n",
        "        \"game_id\", \"game_date\", \"season\",\n",
        "        \"home_team_id\", \"away_team_id\",\n",
        "        \"home_team\", \"away_team\",\n",
        "        \"home_score\", \"away_score\", \"home_win\"\n",
        "    ]\n",
        "\n",
        "    return games[essential_cols]\n",
        "\n",
        "games_historical = transform_historical_to_game_level(raw_games)\n",
        "\n",
        "print(f\"\\n✓ Transformation complete\")\n",
        "print(f\"  Games: {len(games_historical):,}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8 — HISTORICAL VALIDATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Validating historical dataset\")\n",
        "\n",
        "# Check: Chronological ordering\n",
        "assert games_historical[\"game_date\"].is_monotonic_increasing, \\\n",
        "    \"Games not sorted chronologically\"\n",
        "print(\"✓ Chronologically sorted\")\n",
        "\n",
        "# Check: Home win rate per season\n",
        "print(\"\\nHome win rates by season:\")\n",
        "for season in games_historical[\"season\"].unique():\n",
        "    season_games = games_historical[games_historical[\"season\"] == season]\n",
        "    home_win_rate = season_games[\"home_win\"].mean()\n",
        "    status = \"✓\" if 0.53 < home_win_rate < 0.65 else \"⚠\"\n",
        "    print(f\"  {status} {season}: {home_win_rate:.3f}\")\n",
        "\n",
        "# Overall home win rate\n",
        "overall_home_win = games_historical[\"home_win\"].mean()\n",
        "print(f\"\\n✓ Overall home win rate: {overall_home_win:.3f}\")\n",
        "\n",
        "# Check: Games per season\n",
        "games_per_season = games_historical.groupby(\"season\").size()\n",
        "print(\"\\nGames per season:\")\n",
        "for season, count in games_per_season.items():\n",
        "    expected = 1230  # 30 teams × 82 games / 2\n",
        "    status = \"✓\" if 1150 < count < 1300 else \"⚠\"\n",
        "\n",
        "    # Special case: 2019-20 COVID season\n",
        "    if season == \"2019-20\" and 900 < count < 1050:\n",
        "        status = \"✓ (COVID)\"\n",
        "\n",
        "    print(f\"  {status} {season}: {count} games\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9 — SAVE HISTORICAL GAME-LEVEL DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Saving historical game-level data\")\n",
        "\n",
        "games_filepath = save_checkpoint(\n",
        "    games_historical,\n",
        "    \"games_outcomes_historical_2015_2024.csv\",\n",
        "    \"Historical game-level outcomes (2015-2024)\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Historical games saved: {games_filepath}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HISTORICAL DATA COLLECTION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "elapsed_time = (datetime.now() - start_time).total_seconds() / 60\n",
        "\n",
        "print(f\"\\n✓ Collection time: {elapsed_time:.1f} minutes\")\n",
        "print(f\"✓ Seasons collected: {len(successful_seasons)}/{len(HISTORICAL_SEASONS)}\")\n",
        "print(f\"✓ Total games: {len(games_historical):,}\")\n",
        "print(f\"✓ Date range: {games_historical['game_date'].min().date()} to {games_historical['game_date'].max().date()}\")\n",
        "print(f\"✓ Overall home win rate: {overall_home_win:.3f}\")\n",
        "\n",
        "if successful_seasons:\n",
        "    print(f\"\\n✓ Successful seasons:\")\n",
        "    for season in successful_seasons:\n",
        "        print(f\"    • {season}\")\n",
        "\n",
        "if failed_seasons:\n",
        "    print(f\"\\n⚠ Failed seasons (retry recommended):\")\n",
        "    for season in failed_seasons:\n",
        "        print(f\"    • {season}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NEXT STEPS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. Run context features script on historical data\")\n",
        "print(\"2. Run rolling stats with 10 seasons of history\")\n",
        "print(\"3. Train models with 5x more data\")\n",
        "print(\"4. Expected improvements:\")\n",
        "print(\"   • Log loss: 0.650 → 0.620-0.630\")\n",
        "print(\"   • MAE: 7.5 → 6.0-6.5 wins\")\n",
        "print(\"   • More stable feature importance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wNubKbSgJpL",
        "outputId": "bfe24108-c235-48e4-8021-bf80ba13958f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PHASE 2: HISTORICAL DATA COLLECTION (2015-2024)\n",
            "============================================================\n",
            "\n",
            "✓ Configuration:\n",
            "  Seasons to pull: 9\n",
            "  Date range: 2015-16 to 2023-24\n",
            "  Sleep range: 2.0-4.0 seconds\n",
            "  Max retries: 5\n",
            "\n",
            "[1] Locking team identifiers\n",
            "✓ Locked 30 team identifiers\n",
            "\n",
            "  Historical notes:\n",
            "    CHA: Charlotte became Hornets in 2014-15 (from Bobcats)\n",
            "\n",
            "[2] Pulling historical game data\n",
            "  ⏳ This will take 5-10 minutes (10 seasons × ~30 seconds each)\n",
            "\n",
            "  [1/9] Pulling 2015-16...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 2460 total rows\n",
            "    ⏱ ETA: 1.2 minutes remaining\n",
            "\n",
            "  [2/9] Pulling 2016-17...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 4920 total rows\n",
            "    ⏱ ETA: 1.6 minutes remaining\n",
            "\n",
            "  [3/9] Pulling 2017-18...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 7380 total rows\n",
            "    ⏱ ETA: 1.2 minutes remaining\n",
            "\n",
            "  [4/9] Pulling 2018-19...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 9840 total rows\n",
            "    ⏱ ETA: 1.0 minutes remaining\n",
            "\n",
            "  [5/9] Pulling 2019-20...\n",
            "    Attempt 1/5... ✓ 2118 rows\n",
            "    💾 Checkpoint saved: 11958 total rows\n",
            "    ⏱ ETA: 0.7 minutes remaining\n",
            "\n",
            "  [6/9] Pulling 2020-21...\n",
            "    Attempt 1/5... ✓ 2160 rows\n",
            "    💾 Checkpoint saved: 14118 total rows\n",
            "    ⏱ ETA: 0.5 minutes remaining\n",
            "\n",
            "  [7/9] Pulling 2021-22...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 16578 total rows\n",
            "    ⏱ ETA: 0.3 minutes remaining\n",
            "\n",
            "  [8/9] Pulling 2022-23...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 19038 total rows\n",
            "    ⏱ ETA: 0.1 minutes remaining\n",
            "\n",
            "  [9/9] Pulling 2023-24...\n",
            "    Attempt 1/5... ✓ 2460 rows\n",
            "    💾 Checkpoint saved: 21498 total rows\n",
            "\n",
            "\n",
            "[3] Consolidating results\n",
            "✓ Collection complete!\n",
            "  Successful: 9 seasons\n",
            "  Failed: 0 seasons\n",
            "  Total team-game rows: 21,498\n",
            "\n",
            "[4] Running data quality checks\n",
            "\n",
            "Team-game rows per season:\n",
            "  ✓ 2015-16: 2,460 rows (expected ~2,460)\n",
            "  ✓ 2016-17: 2,460 rows (expected ~2,460)\n",
            "  ✓ 2017-18: 2,460 rows (expected ~2,460)\n",
            "  ✓ 2018-19: 2,460 rows (expected ~2,460)\n",
            "  ⚠ 2019-20: 2,118 rows (expected ~2,460)\n",
            "  ⚠ 2020-21: 2,160 rows (expected ~2,460)\n",
            "  ✓ 2021-22: 2,460 rows (expected ~2,460)\n",
            "  ✓ 2022-23: 2,460 rows (expected ~2,460)\n",
            "  ✓ 2023-24: 2,460 rows (expected ~2,460)\n",
            "\n",
            "✓ All rows have team abbreviations\n",
            "\n",
            "✓ Date range: 2015-10-27 to 2024-04-14\n",
            "✓ Unique games: 10,749\n",
            "  Expected team-game rows: 21,498\n",
            "  Actual team-game rows: 21,498\n",
            "\n",
            "[5] Saving raw historical data\n",
            "✓ [2026-01-06 00:58:16] Saved: raw_games_historical_2015_2024.csv\n",
            "  Historical team-game data (2015-2024)\n",
            "  Shape: (21498, 30)\n",
            "✓ Raw data saved: /content/drive/MyDrive/nba_predictor/data/processed/raw_games_historical_2015_2024.csv\n",
            "  Rows: 21,498\n",
            "  Columns: 30\n",
            "  Size: 12.8 MB\n",
            "\n",
            "[6] Transforming to game-level format\n",
            "  Home rows: 10,749\n",
            "  Away rows: 10,749\n",
            "  Merged games: 10,749\n",
            "\n",
            "✓ Transformation complete\n",
            "  Games: 10,749\n",
            "\n",
            "[7] Validating historical dataset\n",
            "✓ Chronologically sorted\n",
            "\n",
            "Home win rates by season:\n",
            "  ✓ 2015-16: 0.589\n",
            "  ✓ 2016-17: 0.584\n",
            "  ✓ 2017-18: 0.579\n",
            "  ✓ 2018-19: 0.593\n",
            "  ✓ 2019-20: 0.551\n",
            "  ✓ 2020-21: 0.544\n",
            "  ✓ 2021-22: 0.544\n",
            "  ✓ 2022-23: 0.580\n",
            "  ✓ 2023-24: 0.543\n",
            "\n",
            "✓ Overall home win rate: 0.568\n",
            "\n",
            "Games per season:\n",
            "  ✓ 2015-16: 1230 games\n",
            "  ✓ 2016-17: 1230 games\n",
            "  ✓ 2017-18: 1230 games\n",
            "  ✓ 2018-19: 1230 games\n",
            "  ⚠ 2019-20: 1059 games\n",
            "  ⚠ 2020-21: 1080 games\n",
            "  ✓ 2021-22: 1230 games\n",
            "  ✓ 2022-23: 1230 games\n",
            "  ✓ 2023-24: 1230 games\n",
            "\n",
            "[8] Saving historical game-level data\n",
            "✓ [2026-01-06 00:58:17] Saved: games_outcomes_historical_2015_2024.csv\n",
            "  Historical game-level outcomes (2015-2024)\n",
            "  Shape: (10749, 10)\n",
            "✓ Historical games saved: /content/drive/MyDrive/nba_predictor/data/processed/games_outcomes_historical_2015_2024.csv\n",
            "\n",
            "============================================================\n",
            "HISTORICAL DATA COLLECTION COMPLETE\n",
            "============================================================\n",
            "\n",
            "✓ Collection time: 1.2 minutes\n",
            "✓ Seasons collected: 9/9\n",
            "✓ Total games: 10,749\n",
            "✓ Date range: 2015-10-27 to 2024-04-14\n",
            "✓ Overall home win rate: 0.568\n",
            "\n",
            "✓ Successful seasons:\n",
            "    • 2015-16\n",
            "    • 2016-17\n",
            "    • 2017-18\n",
            "    • 2018-19\n",
            "    • 2019-20\n",
            "    • 2020-21\n",
            "    • 2021-22\n",
            "    • 2022-23\n",
            "    • 2023-24\n",
            "\n",
            "============================================================\n",
            "NEXT STEPS\n",
            "============================================================\n",
            "\n",
            "1. Run context features script on historical data\n",
            "2. Run rolling stats with 10 seasons of history\n",
            "3. Train models with 5x more data\n",
            "4. Expected improvements:\n",
            "   • Log loss: 0.650 → 0.620-0.630\n",
            "   • MAE: 7.5 → 6.0-6.5 wins\n",
            "   • More stable feature importance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "HISTORICAL DATA PROCESSING PIPELINE\n",
        "\n",
        "Processes 10,749 games (2015-2024) through complete feature pipeline:\n",
        "1. Context features (rest, B2B, trade deadline)\n",
        "2. Rolling stats (L5, L10, exponentially weighted)\n",
        "3. Season normalization\n",
        "4. Enhanced matchup features\n",
        "\n",
        "This is a consolidated pipeline - runs all steps sequentially.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HISTORICAL DATA PROCESSING PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# Trade deadlines for all historical seasons\n",
        "TRADE_DEADLINES = {\n",
        "    \"2015-16\": \"2016-02-18\",\n",
        "    \"2016-17\": \"2017-02-23\",\n",
        "    \"2017-18\": \"2018-02-08\",\n",
        "    \"2018-19\": \"2019-02-07\",\n",
        "    \"2019-20\": \"2020-02-06\",\n",
        "    \"2020-21\": \"2021-03-25\",  # COVID delay\n",
        "    \"2021-22\": \"2022-02-10\",\n",
        "    \"2022-23\": \"2023-02-09\",\n",
        "    \"2023-24\": \"2024-02-08\"\n",
        "}\n",
        "\n",
        "DECAY_ALPHA = 0.95\n",
        "WINDOWS = [5, 10]\n",
        "PRIMARY_WINDOW = 5\n",
        "\n",
        "print(f\"\\n✓ Configuration:\")\n",
        "print(f\"  Seasons: {len(TRADE_DEADLINES)}\")\n",
        "print(f\"  Rolling windows: {WINDOWS}\")\n",
        "print(f\"  Exponential decay alpha: {DECAY_ALPHA}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 1: LOAD HISTORICAL GAMES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 1: CONTEXT FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[1] Loading historical games\")\n",
        "\n",
        "games = pd.read_csv(\"data/raw/games_outcomes_historical_2015_2024.csv\")\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "\n",
        "print(f\"✓ Loaded {len(games):,} games\")\n",
        "print(f\"✓ Date range: {games['game_date'].min().date()} to {games['game_date'].max().date()}\")\n",
        "print(f\"✓ Seasons: {sorted(games['season'].unique())}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 1A: BUILD TEAM SCHEDULE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Building team schedules\")\n",
        "\n",
        "def build_team_schedule(games_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create chronological schedule for each team\"\"\"\n",
        "    home = games_df[[\"game_id\", \"game_date\", \"season\", \"home_team\"]].copy()\n",
        "    home = home.rename(columns={\"home_team\": \"team\"})\n",
        "    home[\"is_home\"] = 1\n",
        "\n",
        "    away = games_df[[\"game_id\", \"game_date\", \"season\", \"away_team\"]].copy()\n",
        "    away = away.rename(columns={\"away_team\": \"team\"})\n",
        "    away[\"is_home\"] = 0\n",
        "\n",
        "    schedule = pd.concat([home, away], ignore_index=True)\n",
        "    schedule = schedule.sort_values([\"team\", \"season\", \"game_date\"]).reset_index(drop=True)\n",
        "\n",
        "    return schedule\n",
        "\n",
        "team_schedule = build_team_schedule(games)\n",
        "\n",
        "print(f\"✓ Team-game rows: {len(team_schedule):,}\")\n",
        "print(f\"✓ Teams: {team_schedule['team'].nunique()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 1B: COMPUTE REST DAYS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Computing rest days (season-aware)\")\n",
        "\n",
        "def compute_rest_days(schedule: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Compute rest days within each season\"\"\"\n",
        "    schedule = schedule.copy()\n",
        "\n",
        "    schedule[\"prev_game_date\"] = (\n",
        "        schedule.groupby([\"team\", \"season\"])[\"game_date\"].shift(1)\n",
        "    )\n",
        "\n",
        "    schedule[\"is_season_opener\"] = schedule[\"prev_game_date\"].isna().astype(int)\n",
        "\n",
        "    schedule[\"rest_days\"] = (\n",
        "        schedule[\"game_date\"] - schedule[\"prev_game_date\"]\n",
        "    ).dt.days\n",
        "\n",
        "    # Season openers: cap at 7 days\n",
        "    schedule[\"rest_days\"] = schedule[\"rest_days\"].fillna(7).astype(int)\n",
        "\n",
        "    # Back-to-back indicator\n",
        "    schedule[\"is_back_to_back\"] = (schedule[\"rest_days\"] == 1).astype(int)\n",
        "\n",
        "    return schedule\n",
        "\n",
        "team_schedule = compute_rest_days(team_schedule)\n",
        "\n",
        "print(f\"✓ Rest days computed\")\n",
        "print(f\"  Range: {team_schedule['rest_days'].min()}-{team_schedule['rest_days'].max()} days\")\n",
        "print(f\"  Back-to-back rate: {team_schedule['is_back_to_back'].mean():.3f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 1C: ADD TRADE DEADLINE FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[4] Adding trade deadline features\")\n",
        "\n",
        "def add_trade_deadline_features(schedule: pd.DataFrame, deadlines: dict) -> pd.DataFrame:\n",
        "    \"\"\"Add days since trade deadline per season\"\"\"\n",
        "    schedule = schedule.copy()\n",
        "\n",
        "    deadlines_dt = {season: pd.to_datetime(date) for season, date in deadlines.items()}\n",
        "\n",
        "    schedule[\"trade_deadline\"] = schedule[\"season\"].map(deadlines_dt)\n",
        "    schedule[\"days_since_deadline\"] = (\n",
        "        schedule[\"game_date\"] - schedule[\"trade_deadline\"]\n",
        "    ).dt.days\n",
        "\n",
        "    schedule[\"days_since_deadline\"] = schedule[\"days_since_deadline\"].clip(-60, 60)\n",
        "    schedule[\"is_post_deadline\"] = (schedule[\"days_since_deadline\"] > 0).astype(int)\n",
        "\n",
        "    return schedule\n",
        "\n",
        "team_schedule = add_trade_deadline_features(team_schedule, TRADE_DEADLINES)\n",
        "\n",
        "print(f\"✓ Trade deadline features added\")\n",
        "print(f\"  Pre-deadline games: {(team_schedule['days_since_deadline'] < 0).sum():,}\")\n",
        "print(f\"  Post-deadline games: {(team_schedule['days_since_deadline'] > 0).sum():,}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 1D: MERGE CONTEXT TO GAME LEVEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Merging context features to game level\")\n",
        "\n",
        "context_cols = [\"game_id\", \"team\", \"rest_days\", \"is_back_to_back\",\n",
        "                \"is_season_opener\", \"days_since_deadline\", \"is_post_deadline\"]\n",
        "\n",
        "# Home team\n",
        "games = games.merge(\n",
        "    team_schedule[context_cols],\n",
        "    left_on=[\"game_id\", \"home_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\").rename(columns={\n",
        "    \"rest_days\": \"home_rest_days\",\n",
        "    \"is_back_to_back\": \"home_b2b\",\n",
        "    \"is_season_opener\": \"home_season_opener\",\n",
        "    \"days_since_deadline\": \"home_days_since_deadline\",\n",
        "    \"is_post_deadline\": \"home_post_deadline\"\n",
        "})\n",
        "\n",
        "# Away team\n",
        "games = games.merge(\n",
        "    team_schedule[context_cols],\n",
        "    left_on=[\"game_id\", \"away_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\").rename(columns={\n",
        "    \"rest_days\": \"away_rest_days\",\n",
        "    \"is_back_to_back\": \"away_b2b\",\n",
        "    \"is_season_opener\": \"away_season_opener\",\n",
        "    \"days_since_deadline\": \"away_days_since_deadline\",\n",
        "    \"is_post_deadline\": \"away_post_deadline\"\n",
        "})\n",
        "\n",
        "# Relative features\n",
        "games[\"rest_advantage\"] = games[\"home_rest_days\"] - games[\"away_rest_days\"]\n",
        "games[\"both_b2b\"] = ((games[\"home_b2b\"] == 1) & (games[\"away_b2b\"] == 1)).astype(int)\n",
        "games[\"deadline_advantage\"] = games[\"home_days_since_deadline\"] - games[\"away_days_since_deadline\"]\n",
        "games[\"both_post_deadline\"] = (\n",
        "    (games[\"home_post_deadline\"] == 1) & (games[\"away_post_deadline\"] == 1)\n",
        ").astype(int)\n",
        "\n",
        "print(\"✓ Context features merged\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 2: ROLLING STATS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 2: ROLLING PERFORMANCE FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[6] Building team game log\")\n",
        "\n",
        "def build_team_game_log(games_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create game log with team performance stats\"\"\"\n",
        "    # Home games\n",
        "    home_log = games_df[[\n",
        "        \"game_id\", \"game_date\", \"season\",\n",
        "        \"home_team\", \"away_team\",\n",
        "        \"home_score\", \"away_score\"\n",
        "    ]].copy()\n",
        "    home_log = home_log.rename(columns={\n",
        "        \"home_team\": \"team\",\n",
        "        \"away_team\": \"opponent\",\n",
        "        \"home_score\": \"pts_scored\",\n",
        "        \"away_score\": \"pts_allowed\"\n",
        "    })\n",
        "    home_log[\"is_home\"] = 1\n",
        "\n",
        "    # Away games\n",
        "    away_log = games_df[[\n",
        "        \"game_id\", \"game_date\", \"season\",\n",
        "        \"away_team\", \"home_team\",\n",
        "        \"away_score\", \"home_score\"\n",
        "    ]].copy()\n",
        "    away_log = away_log.rename(columns={\n",
        "        \"away_team\": \"team\",\n",
        "        \"home_team\": \"opponent\",\n",
        "        \"away_score\": \"pts_scored\",\n",
        "        \"home_score\": \"pts_allowed\"\n",
        "    })\n",
        "    away_log[\"is_home\"] = 0\n",
        "\n",
        "    team_log = pd.concat([home_log, away_log], ignore_index=True)\n",
        "    team_log = team_log.sort_values([\"team\", \"season\", \"game_date\"]).reset_index(drop=True)\n",
        "\n",
        "    team_log[\"net_rating\"] = team_log[\"pts_scored\"] - team_log[\"pts_allowed\"]\n",
        "    team_log[\"won\"] = (team_log[\"pts_scored\"] > team_log[\"pts_allowed\"]).astype(int)\n",
        "\n",
        "    return team_log\n",
        "\n",
        "team_log = build_team_game_log(games)\n",
        "\n",
        "print(f\"✓ Team game log: {len(team_log):,} rows\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 2A: PRECOMPUTE ROLLING STATS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Precomputing rolling stats (L5, L10)\")\n",
        "print(\"  ⏳ This may take 30-60 seconds...\")\n",
        "\n",
        "def precompute_rolling_stats(team_log_df: pd.DataFrame, windows: list) -> pd.DataFrame:\n",
        "    \"\"\"Precompute rolling averages for all windows\"\"\"\n",
        "    log = team_log_df.copy()\n",
        "    grouped = log.groupby([\"team\", \"season\"])\n",
        "\n",
        "    for window in windows:\n",
        "        print(f\"    Computing L{window} window...\")\n",
        "\n",
        "        log[f\"pts_scored_L{window}\"] = (\n",
        "            grouped[\"pts_scored\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        )\n",
        "        log[f\"pts_allowed_L{window}\"] = (\n",
        "            grouped[\"pts_allowed\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        )\n",
        "        log[f\"net_rating_L{window}\"] = (\n",
        "            grouped[\"net_rating\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        )\n",
        "        log[f\"win_rate_L{window}\"] = (\n",
        "            grouped[\"won\"].shift(1).rolling(window, min_periods=1).mean()\n",
        "        )\n",
        "\n",
        "    return log\n",
        "\n",
        "team_log = precompute_rolling_stats(team_log, WINDOWS)\n",
        "\n",
        "print(\"✓ Rolling stats computed\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 2B: EXPONENTIALLY WEIGHTED STATS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Computing exponentially weighted stats\")\n",
        "print(\"  ⏳ This will take 1-2 minutes...\")\n",
        "\n",
        "def add_exponential_weighted_stats(\n",
        "    team_log_df: pd.DataFrame,\n",
        "    alpha: float = 0.95,\n",
        "    window: int = 10\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Add exponentially weighted rolling stats\"\"\"\n",
        "    log = team_log_df.copy()\n",
        "\n",
        "    ew_stats = []\n",
        "\n",
        "    for (team, season), group in log.groupby([\"team\", \"season\"]):\n",
        "        group = group.sort_values(\"game_date\").reset_index(drop=True)\n",
        "\n",
        "        ew_net = []\n",
        "        ew_pts = []\n",
        "        ew_pa = []\n",
        "\n",
        "        for idx in range(len(group)):\n",
        "            if idx == 0:\n",
        "                ew_net.append(np.nan)\n",
        "                ew_pts.append(np.nan)\n",
        "                ew_pa.append(np.nan)\n",
        "            else:\n",
        "                past_games = group.iloc[max(0, idx - window):idx]\n",
        "                n_past = len(past_games)\n",
        "                weights = np.array([alpha ** (n_past - i - 1) for i in range(n_past)])\n",
        "                weights = weights / weights.sum()\n",
        "\n",
        "                ew_net.append(np.average(past_games[\"net_rating\"], weights=weights))\n",
        "                ew_pts.append(np.average(past_games[\"pts_scored\"], weights=weights))\n",
        "                ew_pa.append(np.average(past_games[\"pts_allowed\"], weights=weights))\n",
        "\n",
        "        group[\"net_rating_EW10\"] = ew_net\n",
        "        group[\"pts_scored_EW10\"] = ew_pts\n",
        "        group[\"pts_allowed_EW10\"] = ew_pa\n",
        "\n",
        "        ew_stats.append(group)\n",
        "\n",
        "    return pd.concat(ew_stats, ignore_index=True)\n",
        "\n",
        "team_log = add_exponential_weighted_stats(team_log, alpha=DECAY_ALPHA, window=10)\n",
        "\n",
        "print(\"✓ Exponentially weighted stats computed\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 2C: SAVE ENHANCED CACHE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[9] Saving enhanced rolling stats cache\")\n",
        "\n",
        "cache_path = save_checkpoint(\n",
        "    team_log,\n",
        "    \"team_rolling_stats_historical_enhanced.csv\",\n",
        "    \"Historical rolling stats cache (2015-2024)\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Cache saved: {cache_path}\")\n",
        "print(f\"  Columns: {len(team_log.columns)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 3: MERGE & NORMALIZE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 3: MERGE & NORMALIZATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[10] Merging rolling stats to game level\")\n",
        "\n",
        "# Merge L5 features\n",
        "for window in WINDOWS:\n",
        "    merge_cols = [\n",
        "        \"game_id\", \"team\",\n",
        "        f\"pts_scored_L{window}\", f\"pts_allowed_L{window}\",\n",
        "        f\"net_rating_L{window}\", f\"win_rate_L{window}\"\n",
        "    ]\n",
        "\n",
        "    # Home team\n",
        "    games = games.merge(\n",
        "        team_log[merge_cols],\n",
        "        left_on=[\"game_id\", \"home_team\"],\n",
        "        right_on=[\"game_id\", \"team\"],\n",
        "        how=\"left\",\n",
        "        validate=\"one_to_one\"\n",
        "    ).drop(columns=\"team\").rename(columns={\n",
        "        f\"pts_scored_L{window}\": f\"home_pts_L{window}\",\n",
        "        f\"pts_allowed_L{window}\": f\"home_pa_L{window}\",\n",
        "        f\"net_rating_L{window}\": f\"home_net_L{window}\",\n",
        "        f\"win_rate_L{window}\": f\"home_winpct_L{window}\"\n",
        "    })\n",
        "\n",
        "    # Away team\n",
        "    games = games.merge(\n",
        "        team_log[merge_cols],\n",
        "        left_on=[\"game_id\", \"away_team\"],\n",
        "        right_on=[\"game_id\", \"team\"],\n",
        "        how=\"left\",\n",
        "        validate=\"one_to_one\"\n",
        "    ).drop(columns=\"team\").rename(columns={\n",
        "        f\"pts_scored_L{window}\": f\"away_pts_L{window}\",\n",
        "        f\"pts_allowed_L{window}\": f\"away_pa_L{window}\",\n",
        "        f\"net_rating_L{window}\": f\"away_net_L{window}\",\n",
        "        f\"win_rate_L{window}\": f\"away_winpct_L{window}\"\n",
        "    })\n",
        "\n",
        "# Merge EW10 features\n",
        "ew_cols = [\"game_id\", \"team\", \"net_rating_EW10\", \"pts_scored_EW10\", \"pts_allowed_EW10\"]\n",
        "\n",
        "games = games.merge(\n",
        "    team_log[ew_cols],\n",
        "    left_on=[\"game_id\", \"home_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\").rename(columns={\n",
        "    \"net_rating_EW10\": \"home_net_EW10\",\n",
        "    \"pts_scored_EW10\": \"home_pts_EW10\",\n",
        "    \"pts_allowed_EW10\": \"home_pa_EW10\"\n",
        "})\n",
        "\n",
        "games = games.merge(\n",
        "    team_log[ew_cols],\n",
        "    left_on=[\"game_id\", \"away_team\"],\n",
        "    right_on=[\"game_id\", \"team\"],\n",
        "    how=\"left\",\n",
        "    validate=\"one_to_one\"\n",
        ").drop(columns=\"team\").rename(columns={\n",
        "    \"net_rating_EW10\": \"away_net_EW10\",\n",
        "    \"pts_scored_EW10\": \"away_pts_EW10\",\n",
        "    \"pts_allowed_EW10\": \"away_pa_EW10\"\n",
        "})\n",
        "\n",
        "print(\"✓ Rolling stats merged\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 3A: SEASON-BASED NORMALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[11] Normalizing features within seasons\")\n",
        "\n",
        "def normalize_features(df: pd.DataFrame, windows: list) -> pd.DataFrame:\n",
        "    \"\"\"Normalize rolling features within each season\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Build list of columns to normalize\n",
        "    cols_to_normalize = []\n",
        "\n",
        "    for window in windows:\n",
        "        cols_to_normalize.extend([\n",
        "            f\"home_pts_L{window}\", f\"home_pa_L{window}\", f\"home_net_L{window}\",\n",
        "            f\"away_pts_L{window}\", f\"away_pa_L{window}\", f\"away_net_L{window}\"\n",
        "        ])\n",
        "\n",
        "    cols_to_normalize.extend([\n",
        "        \"home_net_EW10\", \"home_pts_EW10\", \"home_pa_EW10\",\n",
        "        \"away_net_EW10\", \"away_pts_EW10\", \"away_pa_EW10\"\n",
        "    ])\n",
        "\n",
        "    for col in cols_to_normalize:\n",
        "        df[f\"{col}_z\"] = df.groupby(\"season\")[col].transform(\n",
        "            lambda x: (x - x.mean()) / x.std(ddof=0) if x.std(ddof=0) != 0 else 0\n",
        "        )\n",
        "\n",
        "    return df\n",
        "\n",
        "games = normalize_features(games, WINDOWS)\n",
        "\n",
        "print(\"✓ Features normalized\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 3B: CREATE MATCHUP FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[12] Creating matchup features\")\n",
        "\n",
        "# L5 matchup features\n",
        "games[\"net_diff_L5\"] = games[\"home_net_L5_z\"] - games[\"away_net_L5_z\"]\n",
        "games[\"off_vs_def_L5\"] = games[\"home_pts_L5_z\"] - games[\"away_pa_L5_z\"]\n",
        "games[\"winpct_diff_L5\"] = games[\"home_winpct_L5\"] - games[\"away_winpct_L5\"]\n",
        "\n",
        "# L10 matchup features\n",
        "games[\"net_diff_L10\"] = games[\"home_net_L10_z\"] - games[\"away_net_L10_z\"]\n",
        "games[\"off_vs_def_L10\"] = games[\"home_pts_L10_z\"] - games[\"away_pa_L10_z\"]\n",
        "games[\"winpct_diff_L10\"] = games[\"home_winpct_L10\"] - games[\"away_winpct_L10\"]\n",
        "\n",
        "# EW10 matchup features\n",
        "games[\"net_diff_EW10\"] = games[\"home_net_EW10_z\"] - games[\"away_net_EW10_z\"]\n",
        "games[\"off_vs_def_EW10\"] = games[\"home_pts_EW10_z\"] - games[\"away_pa_EW10_z\"]\n",
        "\n",
        "print(\"✓ Matchup features created\")\n",
        "\n",
        "# =============================================================================\n",
        "# STAGE 4: SAVE FINAL DATASET\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[13] Saving final historical dataset\")\n",
        "\n",
        "output_path = save_checkpoint(\n",
        "    games,\n",
        "    \"games_historical_complete_2015_2024.csv\",\n",
        "    \"Complete historical dataset with all features (2015-2024)\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Final dataset saved: {output_path}\")\n",
        "print(f\"  Games: {len(games):,}\")\n",
        "print(f\"  Features: {len(games.columns)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HISTORICAL PIPELINE COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n✓ Processed {len(games):,} games\")\n",
        "print(f\"✓ Seasons: {games['season'].nunique()}\")\n",
        "print(f\"✓ Date range: {games['game_date'].min().date()} to {games['game_date'].max().date()}\")\n",
        "print(f\"✓ Total features: {len(games.columns)}\")\n",
        "\n",
        "print(\"\\n✓ Feature summary:\")\n",
        "print(f\"  Context features: 12\")\n",
        "print(f\"  Rolling features (L5, L10, EW10): ~40\")\n",
        "print(f\"  Matchup features: 9\")\n",
        "print(f\"  Total: {len(games.columns)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"READY FOR HISTORICAL MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nNext step: Train models on historical data\")\n",
        "print(\"Expected improvements:\")\n",
        "print(\"  • 3x more training data (8,289 train games vs 2,460)\")\n",
        "print(\"  • Log loss: 0.650 → 0.620-0.630\")\n",
        "print(\"  • MAE: 7.5 → 6.0-6.5 wins\")\n",
        "print(\"  • More stable feature importance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGr1zyKTij6y",
        "outputId": "23cd2725-76ef-46ee-da82-b9ed4eb960ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "HISTORICAL DATA PROCESSING PIPELINE\n",
            "============================================================\n",
            "\n",
            "✓ Configuration:\n",
            "  Seasons: 9\n",
            "  Rolling windows: [5, 10]\n",
            "  Exponential decay alpha: 0.95\n",
            "\n",
            "============================================================\n",
            "STAGE 1: CONTEXT FEATURES\n",
            "============================================================\n",
            "\n",
            "[1] Loading historical games\n",
            "✓ Loaded 10,749 games\n",
            "✓ Date range: 2015-10-27 to 2024-04-14\n",
            "✓ Seasons: ['2015-16', '2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24']\n",
            "\n",
            "[2] Building team schedules\n",
            "✓ Team-game rows: 21,498\n",
            "✓ Teams: 30\n",
            "\n",
            "[3] Computing rest days (season-aware)\n",
            "✓ Rest days computed\n",
            "  Range: 1-146 days\n",
            "  Back-to-back rate: 0.180\n",
            "\n",
            "[4] Adding trade deadline features\n",
            "✓ Trade deadline features added\n",
            "  Pre-deadline games: 14,190\n",
            "  Post-deadline games: 7,206\n",
            "\n",
            "[5] Merging context features to game level\n",
            "✓ Context features merged\n",
            "\n",
            "============================================================\n",
            "STAGE 2: ROLLING PERFORMANCE FEATURES\n",
            "============================================================\n",
            "\n",
            "[6] Building team game log\n",
            "✓ Team game log: 21,498 rows\n",
            "\n",
            "[7] Precomputing rolling stats (L5, L10)\n",
            "  ⏳ This may take 30-60 seconds...\n",
            "    Computing L5 window...\n",
            "    Computing L10 window...\n",
            "✓ Rolling stats computed\n",
            "\n",
            "[8] Computing exponentially weighted stats\n",
            "  ⏳ This will take 1-2 minutes...\n",
            "✓ Exponentially weighted stats computed\n",
            "\n",
            "[9] Saving enhanced rolling stats cache\n",
            "✓ [2026-01-06 00:58:26] Saved: team_rolling_stats_historical_enhanced.csv\n",
            "  Historical rolling stats cache (2015-2024)\n",
            "  Shape: (21498, 21)\n",
            "✓ Cache saved: /content/drive/MyDrive/nba_predictor/data/processed/team_rolling_stats_historical_enhanced.csv\n",
            "  Columns: 21\n",
            "\n",
            "============================================================\n",
            "STAGE 3: MERGE & NORMALIZATION\n",
            "============================================================\n",
            "\n",
            "[10] Merging rolling stats to game level\n",
            "✓ Rolling stats merged\n",
            "\n",
            "[11] Normalizing features within seasons\n",
            "✓ Features normalized\n",
            "\n",
            "[12] Creating matchup features\n",
            "✓ Matchup features created\n",
            "\n",
            "[13] Saving final historical dataset\n",
            "✓ [2026-01-06 00:58:28] Saved: games_historical_complete_2015_2024.csv\n",
            "  Complete historical dataset with all features (2015-2024)\n",
            "  Shape: (10749, 72)\n",
            "✓ Final dataset saved: /content/drive/MyDrive/nba_predictor/data/processed/games_historical_complete_2015_2024.csv\n",
            "  Games: 10,749\n",
            "  Features: 72\n",
            "\n",
            "============================================================\n",
            "HISTORICAL PIPELINE COMPLETE\n",
            "============================================================\n",
            "\n",
            "✓ Processed 10,749 games\n",
            "✓ Seasons: 9\n",
            "✓ Date range: 2015-10-27 to 2024-04-14\n",
            "✓ Total features: 72\n",
            "\n",
            "✓ Feature summary:\n",
            "  Context features: 12\n",
            "  Rolling features (L5, L10, EW10): ~40\n",
            "  Matchup features: 9\n",
            "  Total: 72\n",
            "\n",
            "============================================================\n",
            "READY FOR HISTORICAL MODEL TRAINING\n",
            "============================================================\n",
            "\n",
            "Next step: Train models on historical data\n",
            "Expected improvements:\n",
            "  • 3x more training data (8,289 train games vs 2,460)\n",
            "  • Log loss: 0.650 → 0.620-0.630\n",
            "  • MAE: 7.5 → 6.0-6.5 wins\n",
            "  • More stable feature importance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NBA Win Probability Predictor\n",
        "HISTORICAL MODEL TRAINING (2015-2024)\n",
        "\n",
        "Trains ensemble on 9 seasons of data with multiple evaluation strategies:\n",
        "1. Single holdout: Train on 2015-2022, test on 2023-24\n",
        "2. Rolling validation: Test on each recent season\n",
        "3. Full ensemble with optimized weights\n",
        "\n",
        "Expected improvements:\n",
        "- Log loss: 0.650 → 0.620-0.630\n",
        "- MAE: 7.5 → 6.0-6.5 wins\n",
        "- More stable feature importance\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "from scipy.optimize import minimize\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# Setup\n",
        "Path(\"evaluation\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HISTORICAL MODEL TRAINING (2015-2024)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD HISTORICAL DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading historical dataset\")\n",
        "\n",
        "games = pd.read_csv(\"data/processed/games_historical_complete_2015_2024.csv\")\n",
        "games[\"game_date\"] = pd.to_datetime(games[\"game_date\"])\n",
        "\n",
        "print(f\"✓ Loaded {len(games):,} games\")\n",
        "print(f\"✓ Features: {len(games.columns)}\")\n",
        "print(f\"✓ Seasons: {sorted(games['season'].unique())}\")\n",
        "\n",
        "# =============================================================================\n",
        "# DEFINE FEATURE SET\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[2] Defining feature set\")\n",
        "\n",
        "context_features = [\n",
        "    \"home_rest_days\", \"away_rest_days\", \"rest_advantage\",\n",
        "    \"home_b2b\", \"away_b2b\", \"both_b2b\",\n",
        "    \"home_days_since_deadline\", \"away_days_since_deadline\",\n",
        "    \"deadline_advantage\", \"both_post_deadline\"\n",
        "]\n",
        "\n",
        "# L5 features\n",
        "l5_features = [\n",
        "    \"home_net_L5_z\", \"away_net_L5_z\",\n",
        "    \"home_pts_L5_z\", \"away_pts_L5_z\",\n",
        "    \"home_pa_L5_z\", \"away_pa_L5_z\",\n",
        "    \"home_winpct_L5\", \"away_winpct_L5\",\n",
        "    \"net_diff_L5\", \"off_vs_def_L5\", \"winpct_diff_L5\"\n",
        "]\n",
        "\n",
        "# L10 features\n",
        "l10_features = [\n",
        "    \"home_net_L10_z\", \"away_net_L10_z\",\n",
        "    \"home_pts_L10_z\", \"away_pts_L10_z\",\n",
        "    \"home_pa_L10_z\", \"away_pa_L10_z\",\n",
        "    \"home_winpct_L10\", \"away_winpct_L10\",\n",
        "    \"net_diff_L10\", \"off_vs_def_L10\", \"winpct_diff_L10\"\n",
        "]\n",
        "\n",
        "# EW features\n",
        "ew_features = [\n",
        "    \"home_net_EW10_z\", \"away_net_EW10_z\",\n",
        "    \"home_pts_EW10_z\", \"away_pts_EW10_z\",\n",
        "    \"home_pa_EW10_z\", \"away_pa_EW10_z\",\n",
        "    \"net_diff_EW10\", \"off_vs_def_EW10\"\n",
        "]\n",
        "\n",
        "all_features = context_features + l5_features + l10_features + ew_features\n",
        "\n",
        "print(f\"✓ Total features: {len(all_features)}\")\n",
        "print(f\"  Context: {len(context_features)}\")\n",
        "print(f\"  L5: {len(l5_features)}\")\n",
        "print(f\"  L10: {len(l10_features)}\")\n",
        "print(f\"  Exponential weighted: {len(ew_features)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# PREPARE DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[3] Preparing data\")\n",
        "\n",
        "y = games[\"home_win\"].astype(int)\n",
        "X = games[all_features].apply(pd.to_numeric, errors=\"coerce\").fillna(games[all_features].mean())\n",
        "\n",
        "print(f\"✓ X shape: {X.shape}\")\n",
        "print(f\"✓ Missing values after imputation: {X.isna().sum().sum()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STRATEGY 1: SINGLE HOLDOUT (2015-2022 TRAIN, 2023-24 TEST)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STRATEGY 1: SINGLE HOLDOUT VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "TRAIN_SEASONS_SINGLE = [\"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\",\n",
        "                        \"2019-20\", \"2020-21\", \"2021-22\", \"2022-23\"]\n",
        "TEST_SEASON_SINGLE = \"2023-24\"\n",
        "\n",
        "print(f\"\\n[4] Creating train/val/test split\")\n",
        "print(f\"  Train: {TRAIN_SEASONS_SINGLE[0]} to {TRAIN_SEASONS_SINGLE[-1]}\")\n",
        "print(f\"  Test: {TEST_SEASON_SINGLE}\")\n",
        "\n",
        "train_mask = games[\"season\"].isin(TRAIN_SEASONS_SINGLE)\n",
        "test_mask = games[\"season\"] == TEST_SEASON_SINGLE\n",
        "\n",
        "X_train_full = X[train_mask].reset_index(drop=True)\n",
        "y_train_full = y[train_mask].reset_index(drop=True)\n",
        "X_test = X[test_mask].reset_index(drop=True)\n",
        "y_test = y[test_mask].reset_index(drop=True)\n",
        "\n",
        "# Validation set (last 10% of training)\n",
        "val_size = int(len(X_train_full) * 0.1)\n",
        "X_train = X_train_full.iloc[:-val_size]\n",
        "y_train = y_train_full.iloc[:-val_size]\n",
        "X_val = X_train_full.iloc[-val_size:]\n",
        "y_val = y_train_full.iloc[-val_size:]\n",
        "\n",
        "print(f\"\\n✓ Train: {len(X_train):,} games\")\n",
        "print(f\"✓ Val: {len(X_val):,} games\")\n",
        "print(f\"✓ Test: {len(X_test):,} games\")\n",
        "print(f\"✓ Train home win rate: {y_train.mean():.3f}\")\n",
        "print(f\"✓ Test home win rate: {y_test.mean():.3f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TRAIN BASELINE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[5] Training baseline\")\n",
        "\n",
        "baseline_prob = y_train.mean()\n",
        "baseline_preds = np.full(len(y_test), baseline_prob)\n",
        "\n",
        "baseline_acc = accuracy_score(y_test, baseline_preds > 0.5)\n",
        "baseline_logloss = log_loss(y_test, baseline_preds)\n",
        "baseline_brier = brier_score_loss(y_test, baseline_preds)\n",
        "\n",
        "print(f\"✓ Baseline (constant {baseline_prob:.3f})\")\n",
        "print(f\"  Accuracy: {baseline_acc:.4f}\")\n",
        "print(f\"  Log Loss: {baseline_logloss:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TRAIN LOGISTIC REGRESSION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[6] Training Logistic Regression\")\n",
        "\n",
        "lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LogisticRegression(\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        max_iter=1000,\n",
        "        solver=\"lbfgs\",\n",
        "        random_state=RANDOM_SEED\n",
        "    ))\n",
        "])\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "lr_probs_val = lr.predict_proba(X_val)[:, 1]\n",
        "lr_probs_test = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "lr_acc = accuracy_score(y_test, lr_probs_test > 0.5)\n",
        "lr_logloss = log_loss(y_test, lr_probs_test)\n",
        "\n",
        "print(f\"✓ Logistic Regression\")\n",
        "print(f\"  Accuracy: {lr_acc:.4f} ({lr_acc - baseline_acc:+.4f})\")\n",
        "print(f\"  Log Loss: {lr_logloss:.4f} ({lr_logloss - baseline_logloss:+.4f})\")\n",
        "\n",
        "# =============================================================================\n",
        "# TRAIN XGBOOST\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[7] Training XGBoost\")\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"logloss\",\n",
        "    \"max_depth\": 4,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"seed\": RANDOM_SEED,\n",
        "}\n",
        "\n",
        "model_xgb = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=500,\n",
        "    evals=[(dval, \"val\")],\n",
        "    early_stopping_rounds=30,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "xgb_probs_val = model_xgb.predict(dval)\n",
        "xgb_probs_test = model_xgb.predict(dtest)\n",
        "\n",
        "xgb_acc = accuracy_score(y_test, xgb_probs_test > 0.5)\n",
        "xgb_logloss = log_loss(y_test, xgb_probs_test)\n",
        "\n",
        "print(f\"✓ XGBoost\")\n",
        "print(f\"  Best iteration: {model_xgb.best_iteration}\")\n",
        "print(f\"  Accuracy: {xgb_acc:.4f} ({xgb_acc - baseline_acc:+.4f})\")\n",
        "print(f\"  Log Loss: {xgb_logloss:.4f} ({xgb_logloss - baseline_logloss:+.4f})\")\n",
        "\n",
        "# =============================================================================\n",
        "# ENSEMBLE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[8] Creating ensemble\")\n",
        "\n",
        "# Simple average\n",
        "ensemble_simple = (lr_probs_test + xgb_probs_test) / 2\n",
        "\n",
        "# Optimized weights\n",
        "def ensemble_loss(w, p1, p2, y_true):\n",
        "    p = w[0] * p1 + w[1] * p2\n",
        "    p = np.clip(p, 1e-15, 1 - 1e-15)\n",
        "    return log_loss(y_true, p)\n",
        "\n",
        "result = minimize(\n",
        "    ensemble_loss,\n",
        "    x0=[0.5, 0.5],\n",
        "    args=(lr_probs_val, xgb_probs_val, y_val),\n",
        "    bounds=[(0, 1), (0, 1)],\n",
        "    constraints={\"type\": \"eq\", \"fun\": lambda w: w.sum() - 1},\n",
        ")\n",
        "\n",
        "optimal_weights = result.x if result.success else np.array([0.5, 0.5])\n",
        "\n",
        "ensemble_weighted = (\n",
        "    optimal_weights[0] * lr_probs_test +\n",
        "    optimal_weights[1] * xgb_probs_test\n",
        ")\n",
        "\n",
        "ensemble_acc = accuracy_score(y_test, ensemble_weighted > 0.5)\n",
        "ensemble_logloss = log_loss(y_test, ensemble_weighted)\n",
        "\n",
        "print(f\"✓ Ensemble (weights: LR={optimal_weights[0]:.2f}, XGB={optimal_weights[1]:.2f})\")\n",
        "print(f\"  Accuracy: {ensemble_acc:.4f} ({ensemble_acc - baseline_acc:+.4f})\")\n",
        "print(f\"  Log Loss: {ensemble_logloss:.4f} ({ensemble_logloss - baseline_logloss:+.4f})\")\n",
        "\n",
        "# =============================================================================\n",
        "# MODEL COMPARISON\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[9] Model comparison\")\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Model\": [\"Baseline\", \"Logistic Regression\", \"XGBoost\", \"Ensemble\"],\n",
        "    \"Accuracy\": [baseline_acc, lr_acc, xgb_acc, ensemble_acc],\n",
        "    \"Log Loss\": [baseline_logloss, lr_logloss, xgb_logloss, ensemble_logloss]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison.to_string(index=False))\n",
        "\n",
        "best_idx = comparison[\"Log Loss\"].idxmin()\n",
        "best_model = comparison.loc[best_idx, \"Model\"]\n",
        "\n",
        "print(f\"\\n✓ Best model: {best_model}\")\n",
        "print(f\"✓ Improvement over original baseline (0.690):\")\n",
        "print(f\"  Log loss: {ensemble_logloss:.4f} (Δ = {0.690 - ensemble_logloss:+.4f})\")\n",
        "\n",
        "# =============================================================================\n",
        "# FEATURE IMPORTANCE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[10] Feature importance analysis\")\n",
        "\n",
        "importance_dict = model_xgb.get_score(importance_type='gain')\n",
        "importance_df = pd.DataFrame([\n",
        "    {'feature': k, 'importance': v}\n",
        "    for k, v in importance_dict.items()\n",
        "]).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 15 features:\")\n",
        "print(importance_df.head(15).to_string(index=False))\n",
        "\n",
        "importance_df.to_csv(\"evaluation/feature_importance_historical.csv\", index=False)\n",
        "\n",
        "# =============================================================================\n",
        "# ROLLING VALIDATION (MULTIPLE TEST SEASONS)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STRATEGY 2: ROLLING VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[11] Testing on multiple recent seasons\")\n",
        "\n",
        "test_seasons = [\"2021-22\", \"2022-23\", \"2023-24\"]\n",
        "rolling_results = []\n",
        "\n",
        "for test_season in test_seasons:\n",
        "    # Train on all prior seasons\n",
        "    train_seasons = [s for s in games[\"season\"].unique() if s < test_season]\n",
        "\n",
        "    train_mask = games[\"season\"].isin(train_seasons)\n",
        "    test_mask = games[\"season\"] == test_season\n",
        "\n",
        "    X_train_roll = X[train_mask]\n",
        "    y_train_roll = y[train_mask]\n",
        "    X_test_roll = X[test_mask]\n",
        "    y_test_roll = y[test_mask]\n",
        "\n",
        "    # Train quick LR model\n",
        "    lr_roll = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lr\", LogisticRegression(penalty=\"l2\", C=1.0, max_iter=1000, random_state=RANDOM_SEED))\n",
        "    ])\n",
        "    lr_roll.fit(X_train_roll, y_train_roll)\n",
        "\n",
        "    probs_roll = lr_roll.predict_proba(X_test_roll)[:, 1]\n",
        "    acc_roll = accuracy_score(y_test_roll, probs_roll > 0.5)\n",
        "    ll_roll = log_loss(y_test_roll, probs_roll)\n",
        "\n",
        "    rolling_results.append({\n",
        "        \"test_season\": test_season,\n",
        "        \"train_games\": len(X_train_roll),\n",
        "        \"test_games\": len(X_test_roll),\n",
        "        \"accuracy\": acc_roll,\n",
        "        \"log_loss\": ll_roll\n",
        "    })\n",
        "\n",
        "    print(f\"  {test_season}: Acc={acc_roll:.4f}, LL={ll_roll:.4f} (trained on {len(train_seasons)} seasons)\")\n",
        "\n",
        "rolling_df = pd.DataFrame(rolling_results)\n",
        "print(\"\\n✓ Rolling validation complete\")\n",
        "print(f\"  Mean accuracy: {rolling_df['accuracy'].mean():.4f}\")\n",
        "print(f\"  Mean log loss: {rolling_df['log_loss'].mean():.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SAVE MODELS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[12] Saving models and results\")\n",
        "\n",
        "# Save models\n",
        "with open(\"models/logistic_regression_historical.pkl\", \"wb\") as f:\n",
        "    pickle.dump(lr, f)\n",
        "\n",
        "model_xgb.save_model(\"models/xgboost_historical.json\")\n",
        "\n",
        "# Save ensemble config\n",
        "ensemble_config = {\n",
        "    \"weights\": optimal_weights.tolist(),\n",
        "    \"models\": [\"logistic_regression\", \"xgboost\"],\n",
        "    \"seed\": RANDOM_SEED,\n",
        "    \"train_seasons\": TRAIN_SEASONS_SINGLE,\n",
        "    \"test_season\": TEST_SEASON_SINGLE\n",
        "}\n",
        "\n",
        "with open(\"models/ensemble_config_historical.json\", \"w\") as f:\n",
        "    json.dump(ensemble_config, f, indent=2)\n",
        "\n",
        "# Save predictions\n",
        "test_results = games[test_mask].reset_index(drop=True).copy()\n",
        "test_results[\"lr_prob\"] = lr_probs_test\n",
        "test_results[\"xgb_prob\"] = xgb_probs_test\n",
        "test_results[\"ensemble_prob\"] = ensemble_weighted\n",
        "test_results[\"actual_home_win\"] = y_test.values\n",
        "\n",
        "test_results.to_csv(\"data/processed/test_predictions_historical.csv\", index=False)\n",
        "\n",
        "print(\"✓ Models saved\")\n",
        "print(\"✓ Predictions saved\")\n",
        "\n",
        "# =============================================================================\n",
        "# VISUALIZATIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n[13] Creating visualizations\")\n",
        "\n",
        "# Calibration plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect\", linewidth=2)\n",
        "\n",
        "for probs, label in [\n",
        "    (lr_probs_test, \"Logistic Regression\"),\n",
        "    (xgb_probs_test, \"XGBoost\"),\n",
        "    (ensemble_weighted, \"Ensemble\"),\n",
        "]:\n",
        "    t, p = calibration_curve(y_test, probs, n_bins=10)\n",
        "    plt.plot(p, t, marker=\"o\", label=label, markersize=6)\n",
        "\n",
        "plt.xlabel(\"Predicted Probability\")\n",
        "plt.ylabel(\"True Probability\")\n",
        "plt.title(\"Calibration Plot - Historical Models (2015-2024)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/calibration_historical.png\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"✓ Calibration plot saved\")\n",
        "\n",
        "# Performance over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "seasons_plot = rolling_df[\"test_season\"]\n",
        "acc_plot = rolling_df[\"accuracy\"]\n",
        "ll_plot = rolling_df[\"log_loss\"]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "ax1.plot(seasons_plot, acc_plot, marker='o', linewidth=2, markersize=8)\n",
        "ax1.set_xlabel(\"Test Season\")\n",
        "ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.set_title(\"Accuracy Over Time\")\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "ax2.plot(seasons_plot, ll_plot, marker='o', linewidth=2, markersize=8, color='orange')\n",
        "ax2.set_xlabel(\"Test Season\")\n",
        "ax2.set_ylabel(\"Log Loss\")\n",
        "ax2.set_title(\"Log Loss Over Time\")\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation/performance_over_time.png\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"✓ Performance over time plot saved\")\n",
        "\n",
        "# =============================================================================\n",
        "# FINAL SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HISTORICAL MODEL TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n✓ Training data: {len(X_train):,} games (2015-2022)\")\n",
        "print(f\"✓ Test data: {len(X_test):,} games (2023-24)\")\n",
        "print(f\"✓ Best model: {best_model}\")\n",
        "print(f\"✓ Test accuracy: {ensemble_acc:.4f}\")\n",
        "print(f\"✓ Test log loss: {ensemble_logloss:.4f}\")\n",
        "\n",
        "print(f\"\\n✓ Improvement vs original 3-season model:\")\n",
        "print(f\"  Original log loss: 0.658\")\n",
        "print(f\"  Historical log loss: {ensemble_logloss:.4f}\")\n",
        "print(f\"  Improvement: {0.658 - ensemble_logloss:.4f} ({100*(0.658-ensemble_logloss)/0.658:.1f}%)\")\n",
        "\n",
        "print(\"\\n✓ Rolling validation (2021-2024):\")\n",
        "print(f\"  Mean accuracy: {rolling_df['accuracy'].mean():.4f}\")\n",
        "print(f\"  Mean log loss: {rolling_df['log_loss'].mean():.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROJECT PHASE 2 COMPLETE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TpzBbf6kjFWh",
        "outputId": "d205b1bf-dfb6-4c76-cbf9-7ec07d406d7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "HISTORICAL MODEL TRAINING (2015-2024)\n",
            "============================================================\n",
            "\n",
            "[1] Loading historical dataset\n",
            "✓ Loaded 10,749 games\n",
            "✓ Features: 72\n",
            "✓ Seasons: ['2015-16', '2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24']\n",
            "\n",
            "[2] Defining feature set\n",
            "✓ Total features: 40\n",
            "  Context: 10\n",
            "  L5: 11\n",
            "  L10: 11\n",
            "  Exponential weighted: 8\n",
            "\n",
            "[3] Preparing data\n",
            "✓ X shape: (10749, 40)\n",
            "✓ Missing values after imputation: 0\n",
            "\n",
            "============================================================\n",
            "STRATEGY 1: SINGLE HOLDOUT VALIDATION\n",
            "============================================================\n",
            "\n",
            "[4] Creating train/val/test split\n",
            "  Train: 2015-16 to 2022-23\n",
            "  Test: 2023-24\n",
            "\n",
            "✓ Train: 8,568 games\n",
            "✓ Val: 951 games\n",
            "✓ Test: 1,230 games\n",
            "✓ Train home win rate: 0.571\n",
            "✓ Test home win rate: 0.543\n",
            "\n",
            "[5] Training baseline\n",
            "✓ Baseline (constant 0.571)\n",
            "  Accuracy: 0.5431\n",
            "  Log Loss: 0.6910\n",
            "\n",
            "[6] Training Logistic Regression\n",
            "✓ Logistic Regression\n",
            "  Accuracy: 0.6488 (+0.1057)\n",
            "  Log Loss: 0.6350 (-0.0560)\n",
            "\n",
            "[7] Training XGBoost\n",
            "✓ XGBoost\n",
            "  Best iteration: 35\n",
            "  Accuracy: 0.6512 (+0.1081)\n",
            "  Log Loss: 0.6360 (-0.0551)\n",
            "\n",
            "[8] Creating ensemble\n",
            "✓ Ensemble (weights: LR=0.50, XGB=0.50)\n",
            "  Accuracy: 0.6496 (+0.1065)\n",
            "  Log Loss: 0.6344 (-0.0567)\n",
            "\n",
            "[9] Model comparison\n",
            "\n",
            "              Model  Accuracy  Log Loss\n",
            "           Baseline     0.543     0.691\n",
            "Logistic Regression     0.649     0.635\n",
            "            XGBoost     0.651     0.636\n",
            "           Ensemble     0.650     0.634\n",
            "\n",
            "✓ Best model: Ensemble\n",
            "✓ Improvement over original baseline (0.690):\n",
            "  Log loss: 0.6344 (Δ = +0.0556)\n",
            "\n",
            "[10] Feature importance analysis\n",
            "\n",
            "Top 15 features:\n",
            "                 feature  importance\n",
            "            net_diff_L10      45.919\n",
            "           net_diff_EW10      25.807\n",
            "          rest_advantage       9.765\n",
            "         winpct_diff_L10       8.820\n",
            "                away_b2b       8.397\n",
            "          home_net_L10_z       8.368\n",
            "          away_rest_days       8.288\n",
            "         home_net_EW10_z       8.126\n",
            "         away_winpct_L10       7.704\n",
            "          away_pa_EW10_z       7.549\n",
            "         home_winpct_L10       7.481\n",
            "home_days_since_deadline       7.472\n",
            "           away_net_L5_z       7.302\n",
            "          off_vs_def_L10       7.271\n",
            "           home_net_L5_z       7.177\n",
            "\n",
            "============================================================\n",
            "STRATEGY 2: ROLLING VALIDATION\n",
            "============================================================\n",
            "\n",
            "[11] Testing on multiple recent seasons\n",
            "  2021-22: Acc=0.6203, LL=0.6578 (trained on 6 seasons)\n",
            "  2022-23: Acc=0.6171, LL=0.6609 (trained on 7 seasons)\n",
            "  2023-24: Acc=0.6463, LL=0.6351 (trained on 8 seasons)\n",
            "\n",
            "✓ Rolling validation complete\n",
            "  Mean accuracy: 0.6279\n",
            "  Mean log loss: 0.6513\n",
            "\n",
            "[12] Saving models and results\n",
            "✓ Models saved\n",
            "✓ Predictions saved\n",
            "\n",
            "[13] Creating visualizations\n",
            "✓ Calibration plot saved\n",
            "✓ Performance over time plot saved\n",
            "\n",
            "============================================================\n",
            "HISTORICAL MODEL TRAINING COMPLETE\n",
            "============================================================\n",
            "\n",
            "✓ Training data: 8,568 games (2015-2022)\n",
            "✓ Test data: 1,230 games (2023-24)\n",
            "✓ Best model: Ensemble\n",
            "✓ Test accuracy: 0.6496\n",
            "✓ Test log loss: 0.6344\n",
            "\n",
            "✓ Improvement vs original 3-season model:\n",
            "  Original log loss: 0.658\n",
            "  Historical log loss: 0.6344\n",
            "  Improvement: 0.0236 (3.6%)\n",
            "\n",
            "✓ Rolling validation (2021-2024):\n",
            "  Mean accuracy: 0.6279\n",
            "  Mean log loss: 0.6513\n",
            "\n",
            "============================================================\n",
            "PROJECT PHASE 2 COMPLETE!\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Find all CSV files in your Drive\n",
        "print(\"Searching for nba_predictor files...\")\n",
        "search_paths = [\n",
        "    \"/content/drive/MyDrive/**/nba_predictor/**/*.csv\",\n",
        "    \"/content/drive/MyDrive/**/*historical*.csv\",\n",
        "    \"/content/drive/MyDrive/**/*games*.csv\"\n",
        "]\n",
        "\n",
        "for pattern in search_paths:\n",
        "    files = glob.glob(pattern, recursive=True)\n",
        "    if files:\n",
        "        print(f\"\\nFound {len(files)} files matching pattern:\")\n",
        "        for f in files[:10]:  # Show first 10\n",
        "            print(f\"  • {f}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H02Mp5HRjxHp",
        "outputId": "b851491c-a58e-4ee6-a129-b438c72c2d98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for nba_predictor files...\n",
            "\n",
            "Found 30 files matching pattern:\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/raw_games_historical_2015_2024.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/games_outcomes_historical_2015_2024.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/team_reference.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2015_16.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2016_17.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2017_18.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2018_19.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2019_20.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2020_21.csv\n",
            "  • /content/drive/MyDrive/nba_predictor/data/raw/checkpoint_after_2021_22.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "oYLmef447_K-"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}